{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3c4e4c-b607-4ade-896f-d5c64f6fa16c",
   "metadata": {},
   "source": [
    "# final_05_2025.ipynb\n",
    "\n",
    "Building cohort, data processing, classification, # of clusters, latent space extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a6af68-8367-475d-a260-96a1933e4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from triton==3.3.1->torch) (69.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ff29de9-708d-4cc6-a969-6ac0c54f6db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "import umap.umap_ as umap\n",
    "import umap.plot\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score, davies_bouldin_score, normalized_mutual_info_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, normalize, label_binarize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import HDBSCAN, KMeans, DBSCAN, SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.cluster.hierarchy import fcluster, linkage, dendrogram\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c23b9f15-0d7d-4a0c-bec8-8cd2a01edeb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mimic4_path = '/global/cfs/projectdirs/m1532/Projects_MVP/_datasets/MIMIC_IV/physionet.org/files/mimiciv/2.2/'\n",
    "root_path = '/global/cfs/projectdirs/m1532/Projects_MVP/Sophia/2024/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098eabae-aa21-4a29-aaf4-c30d6018cff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92a976a6-eb43-4d4f-a9bc-694cbe89ab7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify(race):\n",
    "    if 'BLACK' in race:\n",
    "        return 'B'\n",
    "    elif 'WHITE' in race:\n",
    "        return 'W'\n",
    "    else:\n",
    "        return 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5dc4951-2172-4075-943f-4e4c35f2a3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_group(row):\n",
    "    if (row['osa'] == True)and (row['hf'] == False):\n",
    "        return 0 # OSA only\n",
    "    elif (row['osa'] == True)and (row['hf'] == True):\n",
    "        return 1 # OSA & HF\n",
    "    elif (row['osa'] == False)and (row['hf'] == True):\n",
    "        return 2 # HF only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8002806-3d1f-42ca-a431-b067d81b9742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#- can use group instead.\n",
    "def group_str(group_int):\n",
    "    if group_int == 0:\n",
    "        return 'OSA Only'\n",
    "    elif group_int == 1:\n",
    "        return 'OSA & HF'\n",
    "    else:\n",
    "        return 'HF Only' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bce6340-5ff3-4c8f-a0e6-d2eb8ab74000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#- need to adjust based on cohort.\n",
    "def read_cohort_without_id(file):\n",
    "    cohort_df = pd.read_csv(file).drop(columns = ['Unnamed: 0'], errors='ignore') \n",
    "    cohort_df['group_name'] = cohort_df['group'].apply(group_str)\n",
    "    # Group counts\n",
    "    group_counts = cohort_df['group_name'].value_counts()\n",
    "    hf_count = group_counts['HF Only']\n",
    "    osa_count = group_counts['OSA Only']\n",
    "\n",
    "    # Downsample \"HF Only\" group\n",
    "    hf_df = cohort_df[cohort_df['group_name'] == 'HF Only']\n",
    "    osa_df = cohort_df[cohort_df['group_name'] == 'OSA Only']\n",
    "    osa_hf_df = cohort_df[cohort_df['group_name'] == 'OSA & HF']\n",
    "\n",
    "    # Downsample \"HF Only\" to the same size as \"OSA Only\"\n",
    "    hf_df_downsampled = hf_df.sample(n=osa_count, random_state=42)\n",
    "\n",
    "    # Combine the downsampled \"HF Only\" group with the other groups\n",
    "    downsampled_cohort_df = pd.concat([hf_df_downsampled, osa_df, osa_hf_df])\n",
    "    X = downsampled_cohort_df.drop(columns = ['subject_id', 'hadm_id', 'group', 'group_name'], errors='ignore')\n",
    "    Y = downsampled_cohort_df['group']\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88e45dcd-3932-42d3-a531-c40ed8c8a2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#- need to adjust based on cohort.\n",
    "def read_cohort_with_id(cohort_df):\n",
    "    # cohort_df = pd.read_csv(file).drop(columns = ['Unnamed: 0'], errors='ignore') \n",
    "    cohort_df['group_name'] = cohort_df['group'].apply(group_str)\n",
    "    # Group counts\n",
    "    group_counts = cohort_df['group_name'].value_counts()\n",
    "    hf_count = group_counts['HF Only']\n",
    "    osa_count = group_counts['OSA Only']\n",
    "\n",
    "    # Downsample \"HF Only\" group\n",
    "    hf_df = cohort_df[cohort_df['group_name'] == 'HF Only']\n",
    "    osa_df = cohort_df[cohort_df['group_name'] == 'OSA Only']\n",
    "    osa_hf_df = cohort_df[cohort_df['group_name'] == 'OSA & HF']\n",
    "\n",
    "    # Downsample \"HF Only\" to the same size as \"OSA Only\"\n",
    "    hf_df_downsampled = hf_df.sample(n=osa_count, random_state=42)\n",
    "\n",
    "    # Combine the downsampled \"HF Only\" group with the other groups\n",
    "    downsampled_cohort_df = pd.concat([hf_df_downsampled, osa_df, osa_hf_df])\n",
    "    X = downsampled_cohort_df\n",
    "    Y = downsampled_cohort_df['group']\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d1ace45-b1eb-423f-9c91-c1a63987bbd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df, one_hot_cols, drop_id=True):\n",
    "    # Initialize the one-hot encoder\n",
    "    one_hot_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    # Fit and transform the columns with the encoder\n",
    "    one_hot_encoded_data = one_hot_encoder.fit_transform(df[one_hot_cols])\n",
    "    # Convert the result into a DataFrame with appropriate column names\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded_data, columns=one_hot_encoder.get_feature_names_out(one_hot_cols))\n",
    "    # Drop the original nominal columns from the dataset\n",
    "    data = df.drop(one_hot_cols, axis=1)\n",
    "    \n",
    "    # Concatenate the one-hot encoded columns with the original dataset\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    one_hot_df.reset_index(drop=True, inplace=True)\n",
    "    data_1 = pd.concat([data, one_hot_df], axis=1)\n",
    "\n",
    "    # Display the first few rows of the dataset after one-hot encoding\n",
    "    if drop_id:\n",
    "        data_final = data_1.drop(['subject_id', 'hadm_id', 'osa', 'hf', 'text', 'group_name'], axis = 1)\n",
    "    else:\n",
    "        data_final = data_1.drop(['osa', 'hf', 'text', 'group_name'], axis = 1)\n",
    "    return data_final                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec87465e-6498-45a1-b174-f5af85ec7fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_models(X, Y):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', C=0.2, max_iter=5000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=50),\n",
    "        #-'Support Vector Machine': SVC(probability=True)\n",
    "    }\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}\")\n",
    "        start_time = time.time()\n",
    "        scores = cross_val_score(model, X, Y, scoring='roc_auc_ovr_weighted', cv=cv, n_jobs=128, verbose=True)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            'mean_score': np.mean(scores),\n",
    "            'std_score': np.std(scores),\n",
    "            'runtime': end_time - start_time\n",
    "        }\n",
    "        \n",
    "        print(f'{model_name} - KFold-Results: Mean ROC AUC: {results[model_name][\"mean_score\"]:.3f} (Std: {results[model_name][\"std_score\"]:.3f})')\n",
    "        print(f\"{model_name} - Runtime: {results[model_name]['runtime']:.6f} seconds\\n\")\n",
    "        \n",
    "    rf_model = models.get('Random Forest')\n",
    "    \n",
    "    for train_index, test_index in cv.split(X, Y):\n",
    "        rf_model=rf_model.fit(X.iloc[train_index], Y.iloc[train_index])\n",
    "        y_train_preds = rf_model.predict(X.iloc[train_index])\n",
    "        y_test_preds = rf_model.predict(X.iloc[test_index])\n",
    "\n",
    "        print(\"training results\")\n",
    "        print(classification_report(Y.iloc[train_index].values, y_train_preds))\n",
    "        print(confusion_matrix(Y.iloc[train_index].values, y_train_preds))\n",
    "        #print(\"roc_auc_score:\", roc_auc_score(Y.iloc[train_index].values, y_train_preds, multi_class = 'ovr'))\n",
    "        #print(\"f1_score:\", f1_score(Y.iloc[train_index].values, y_train_preds))\n",
    "        print(\"testing results\")\n",
    "        print(classification_report(Y.iloc[test_index].values, y_test_preds))\n",
    "        print(confusion_matrix(Y.iloc[test_index].values, y_test_preds))\n",
    "        #print(\"roc_auc_score:\", roc_auc_score(Y.iloc[test_index].values, y_test_preds, multi_class = 'ovr'))\n",
    "        #print(\"f1_score:\",f1_score(Y.iloc[test_index].values, y_test_preds))\n",
    "\n",
    "        break\n",
    "    \n",
    "    return results, rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "634ee957-b45a-4876-9bee-b80daf7a0a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels should be \n",
    "def extract_n_feature_importance(X, rf_model, num_features=25, labels={}, specified_feature_list=[]):\n",
    "        \"\"\"\n",
    "    Extract and visualize the top `n` most important features from a trained \n",
    "    Random Forest model using the Mean Decrease in Impurity (MDI) method.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas.DataFrame\n",
    "        The feature matrix used for training the Random Forest model. \n",
    "        Columns represent the features.\n",
    "        \n",
    "    rf_model : sklearn.ensemble.RandomForestClassifier or RandomForestRegressor\n",
    "        The trained Random Forest model from which to extract feature importances.\n",
    "        \n",
    "    num_features : int, optional, default=25\n",
    "        The number of top features to display based on their importance. If `num_features`\n",
    "        exceeds the number of features in X, the function will display all features.\n",
    "        \n",
    "    labels : dict, optional, default={}\n",
    "        A dictionary to map feature names to more descriptive labels in the output. \n",
    "        If provided, the keys should be feature names from `X.columns`, and the values \n",
    "        should be the corresponding labels to use in the plot.\n",
    "        \n",
    "    specified_feature_list : list, optional, default=[]\n",
    "        A list of specific features to highlight in the visualization. \n",
    "        If provided, these features will be emphasized in the plot.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    all_feature_importance_count_dict : dict\n",
    "        A dictionary containing the importance values for all features in `X`. \n",
    "        The keys are the feature names, and the values are the importance scores.\n",
    "    \n",
    "    Visual Output:\n",
    "    --------------\n",
    "    A bar plot showing the top `n` feature importances, with the corresponding \n",
    "    standard deviation bars if available. The plot title and labels are customized \n",
    "    based on the input parameters.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function sorts the features by their importance in descending order and \n",
    "      displays the top `num_features`.\n",
    "    - If `labels` are provided, the feature names will be replaced with the specified labels.\n",
    "    - This function is intended for use with Random Forest models trained using \n",
    "      scikit-learn's `RandomForestClassifier` or `RandomForestRegressor`.\n",
    "    \n",
    "    Example Usage:\n",
    "    --------------\n",
    "    >>> feature_importance_dict = extract_n_feature_importance(X, rf_model, num_features=30, labels=feature_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "        importances = rf_model.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
    "\n",
    "        # print(importances.shape)\n",
    "\n",
    "        #- Sort the feature importance in descending order\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        feature_labels=X.columns\n",
    "\n",
    "        #- Display the top 25 important features.\n",
    "        feature_importance_count_dict  = {}\n",
    "        for f in range(num_features):\n",
    "            feature_importance_count_dict[feature_labels[sorted_indices[f]]] = importances[sorted_indices[f]]\n",
    "            # print(f, feature_labels[sorted_indices[f]])\n",
    "\n",
    "        std = std[:num_features]\n",
    "        std.shape\n",
    "\n",
    "        feature_importances_count = pd.Series(feature_importance_count_dict).rename(labels)\n",
    "        feature_importances_count.shape\n",
    "\n",
    "        all_feature_importance_count_dict  = {}\n",
    "        for f in range(len(importances)):\n",
    "            all_feature_importance_count_dict[feature_labels[sorted_indices[f]]] = importances[sorted_indices[f]]\n",
    "            # print(f, feature_labels[sorted_indices[f]])\n",
    "\n",
    "        for label, value in feature_importances_count.items():\n",
    "            print(f\"{label}: {value}\")\n",
    "\n",
    "        #fig, ax = plt.subplots()\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_axes([0,0,2,1])\n",
    "        feature_importances_count.plot.bar(y=std, ax=ax, width=.8)\n",
    "        ax.set_title(\"Feature importances using MDI\")\n",
    "        ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        return all_feature_importance_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a64caa9-a969-437f-a86b-e6e49823192e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_specified_feature_importance(all_feature_importance_count_dict={}, feature_list=[], num_features=50, labels={}):\n",
    "    specified_feature_importance = {}\n",
    "    for k, v in all_feature_importance_count_dict.items():\n",
    "        if k in feature_list:\n",
    "            specified_feature_importance[k] = v\n",
    "        \n",
    "    print(specified_feature_importance)\n",
    "    \n",
    "    specified_feature_importance_count = pd.Series(specified_feature_importance).rename(labels)\n",
    "    specified_feature_importance_count.shape\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,2,1])\n",
    "    specified_feature_importance_count.plot.bar(y=std, ax=ax, width=.8)\n",
    "    ax.set_title(\"Feature importances\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    # fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63c2ed06-1778-4c0a-81ec-35a23aca1156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def umap_embedding(X, n_neighbors=15, min_dist=0.1, n_components=2, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform UMAP embedding on the dataset X with the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - X: The feature dataset to be transformed.\n",
    "    - n_neighbors: The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation.\n",
    "    - min_dist: The minimum distance between points in the low-dimensional space.\n",
    "    - n_components: The number of dimensions of the low-dimensional space.\n",
    "    - random_state: The seed used by the random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - clusterable_embedding: The transformed feature dataset.\n",
    "    - runtime: The time taken to perform the UMAP embedding.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    clusterable_embedding = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        random_state=random_state\n",
    "    ).fit_transform(X)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the runtime\n",
    "    runtime = end_time - start_time\n",
    "    print(f\"UMAP Runtime: {runtime:.6f} seconds\")\n",
    "    \n",
    "    return clusterable_embedding, runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b7d7b96-bc48-4994-82c1-1b5b0b2629b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_umap_embedding(clusterable_embedding, labels, group, colors=None, n_clusters=None, title='UMAP Embedding', xlabel='Embedding-1', ylabel='Embedding-2', background_color='white', point_size=0.1, point_alpha=0.5):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot of UMAP embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - clusterable_embedding: The transformed feature dataset.\n",
    "    - labels: The cluster labels for each data point.\n",
    "    - group: The unique number for each group.\n",
    "    - colors: A list of colors to use for the clusters.\n",
    "    - n_clusters: The number of clusters.\n",
    "    - title: The title of the plot.\n",
    "    - xlabel: The label for the x-axis.\n",
    "    - ylabel: The label for the y-axis.\n",
    "    - background_color: The background color of the plot.\n",
    "    - point_size: The size of the points in the scatter plot.\n",
    "    - point_alpha: The alpha transparency for the points.\n",
    "    \"\"\"\n",
    "    if colors is None:\n",
    "        colors = ['orange', 'green', 'blue']  # Default colors if none provided\n",
    "    if n_clusters is None:\n",
    "        n_clusters = len(group)\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(colors[:n_clusters])\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(background_color)\n",
    "    \n",
    "    sc = plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], c=labels, s=point_size, alpha=point_alpha, cmap=cmap)\n",
    "    \n",
    "    labels_group_str = labels.apply(group_str)\n",
    "    \n",
    "    cbar = fig.colorbar(sc)\n",
    "    cbar.set_ticks(group)\n",
    "    cbar.set_ticklabels(labels_group_str.unique())\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a97f9-e902-457a-9fc6-4bd8506d95c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed1bd377-ce5c-44b6-8aaa-9c7c60f0838f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-\n",
    "def apply_pca_with_n_components(data, n_components):\n",
    "    \"\"\"\n",
    "    Applies PCA to the given data with n number of components.\n",
    "\n",
    "    Parameters:\n",
    "    - data: ndarray of shape (n_samples, n_features) The input data to perform PCA on.\n",
    "    \n",
    "    Returns:\n",
    "    - pca_data: ndarray of shape (n_samples, n_components) The transformed data with the selected PCA components.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Apply PCA with the selected number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    \n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0251c2c5-7e8d-4013-ba6e-764311e581a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-\n",
    "def train_models_results(X, Y):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(solver='lbfgs', penalty='l2', C=0.2, max_iter=5000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=50),\n",
    "        #-'Support Vector Machine': SVC(probability=True)\n",
    "    }\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}\")\n",
    "        start_time = time.time()\n",
    "        scores = cross_val_score(model, X, Y, scoring='roc_auc_ovr_weighted', cv=cv, n_jobs=128, verbose=True)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            'mean_score': np.mean(scores),\n",
    "            'std_score': np.std(scores),\n",
    "            'runtime': end_time - start_time\n",
    "        }\n",
    "        \n",
    "        print(f'{model_name} - KFold-Results: Mean ROC AUC: {results[model_name][\"mean_score\"]:.3f} (Std: {results[model_name][\"std_score\"]:.3f})')\n",
    "        print(f\"{model_name} - Runtime: {results[model_name]['runtime']:.6f} seconds\\n\")\n",
    "    \n",
    "    return results[model_name][\"mean_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b251765f-92d3-4dca-b272-85d2fc0d6442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-\n",
    "def score_pca(X, Y, n_components):\n",
    "    \"\"\"\n",
    "    Get wAUC score of RF model using PCA\n",
    "\n",
    "    Parameters:\n",
    "    - X: ndarray of shape (n_samples, n_features) The input data to perform PCA on.\n",
    "    - Y: The labels.\n",
    "    - n_components: int The number of components selected\n",
    "\n",
    "    Returns:\n",
    "    - score: float Average reconstruction error of RF model using PCA\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Apply PCA\n",
    "    pca_data = apply_pca_with_n_components(X, n_components)\n",
    "    end_time = time.time()\n",
    "    print(\"Runtime for PCA: \", end_time - start_time)\n",
    "\n",
    "    #-\n",
    "    score = train_models_results(pca_data, Y)\n",
    "\n",
    "    return score, pca_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1aefa8-3f07-4fa4-8cfb-06a31f5090dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7fa95dba-5de0-401d-9b9e-0c9e6b40b290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Make sure CUDA operations are deterministic\n",
    "    torch.backends.cudnn.benchmark = False  # Disable CUDA's auto-tuner that finds the best algorithm to use for your hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29a8de6a-45cd-4f4c-aee4-b2bbb27af130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#- sparse data\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dims):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.LeakyReLU(0.2),  # LeakyReLU\n",
    "            nn.Linear(400, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(100, encoding_dims),\n",
    "            nn.BatchNorm1d(encoding_dims),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dims, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(100, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(200, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(400, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    #- for DAE only\n",
    "    def add_noise(self, x, noise_factor=0.3):\n",
    "        noisy = x + noise_factor * torch.randn_like(x)\n",
    "        noisy = torch.clip(noisy, 0., 1.)\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e1686-a67e-4a12-a8e9-7489e08026d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dcf542b9-97fc-4934-b865-126ffc723043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_and_return_optimal_clusters(data, k_range=(4, 30), metrics=['silhouette', 'calinski_harabasz']):\n",
    "    \"\"\"\n",
    "    Plot multiple elbow plots in subplots for different evaluation metrics with K-means clustering.\n",
    "    Returns the optimal number of clusters for each metric.\n",
    "\n",
    "    Parameters:\n",
    "    data (array-like): The input data to cluster.\n",
    "    k_range (tuple): Range of number of clusters to test. Default is (2, 20).\n",
    "    metrics (list): List of metrics to use for evaluation. Options include 'silhouette', 'calinski_harabasz'\n",
    "                    Default is ['silhouette', 'calinski_harabasz', 'davies_bouldin'].\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the optimal number of clusters for each metric.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(metrics), 1, figsize=(10, 6 * len(metrics)))\n",
    "    optimal_clusters = {}\n",
    "\n",
    "\n",
    "    for i, metric in enumerate(metrics, start=0):\n",
    "        if metric == 'silhouette' or metric == 'calinski_harabasz':\n",
    "            model = KMeans()\n",
    "            visualizer = KElbowVisualizer(model, k=k_range, metric=metric, timings=False, ax=axes[i])\n",
    "            visualizer.fit(data)\n",
    "            visualizer.finalize()\n",
    "            optimal_clusters[metric] = visualizer.elbow_value_\n",
    "        else:\n",
    "            print(f\"Warning: Metric '{metric}' is not supported for KElbowVisualizer. Skipping.\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return optimal_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce1a77cb-1e6d-46cb-b83a-f7edb6ca1281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_kmeans_davies_bouldin_score(data, center):\n",
    "    '''\n",
    "    returns the kmeans score regarding Davies Bouldin for points to centers\n",
    "    INPUT:\n",
    "        data - the dataset you want to fit kmeans to\n",
    "        center - the number of centers you want (the k value)\n",
    "    OUTPUT:\n",
    "        score - the Davies Bouldin score for the kmeans model fit to the data\n",
    "    '''\n",
    "    #instantiate kmeans\n",
    "    kmeans = KMeans(n_clusters=center)\n",
    "    # Then fit the model to your data using the fit method\n",
    "    model = kmeans.fit_predict(data)\n",
    "    \n",
    "    # Calculate Davies Bouldin score\n",
    "    score = davies_bouldin_score(data, model)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97176527-d05d-4d73-9a3e-9c13a2346891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  get_kmeans_gap_statistic(data, nrefs=3, maxClusters=20):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic \n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "# Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "# For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "            # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        \n",
    "        new_row = pd.DataFrame({'clusterCount': [k], 'gap': [gap]})\n",
    "\n",
    "        # Use concat to concatenate the new row to resultsdf\n",
    "        resultsdf = pd.concat([resultsdf, new_row], ignore_index=True)\n",
    "    \n",
    "        \n",
    "        #resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "    return (gaps.argmax() + 1, resultsdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ddd0fc9-beda-47f8-a3ec-041c5d62f708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_kmeans(data, n_clusters=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on the given data and evaluate the clustering.\n",
    "\n",
    "    Parameters:\n",
    "    data (array-like): The input data to cluster.\n",
    "    n_clusters (int): The number of clusters to form.\n",
    "    plot_tsne (bool): Whether to plot the t-SNE visualization.\n",
    "    random_state (int): The seed used by the random number generator.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Fit K-means\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(data)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # Calculate metrics\n",
    "    silhouette_avg = silhouette_score(data, labels)\n",
    "    db_index = davies_bouldin_score(data, labels)\n",
    "    wcss = kmeans.inertia_\n",
    "    \n",
    "    metrics = {\n",
    "        'Silhouette Score': silhouette_avg, #--high Measures how similar each point is to its own cluster compared to other clusters.\n",
    "        'Davies-Bouldin Index': db_index,  #- low Measures the average similarity ratio of each cluster with its most similar cluster.\n",
    "        'WCSS': wcss                       #- low compactness\n",
    "    }\n",
    "    \n",
    "    #print(f'Silhouette Score: {silhouette_avg}')\n",
    "    #print(f'Davies-Bouldin Index: {db_index}')\n",
    "    #print(f'Within-Cluster Sum of Squares (WCSS): {wcss}')\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8bbb0599-f78b-4599-b62d-07da28bb98e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_gmm(data, n_components=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Model (GMM) clustering on the given data and evaluate the clustering.\n",
    "\n",
    "    Parameters:\n",
    "    data (array-like): The input data to cluster.\n",
    "    n_components (int): The number of Gaussian components.\n",
    "    plot_tsne (bool): Whether to plot the t-SNE visualization.\n",
    "    random_state (int): The seed used by the random number generator.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Fit GMM\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=random_state).fit(data)\n",
    "    labels = gmm.predict(data)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    silhouette_avg = silhouette_score(data, labels)\n",
    "    db_index = davies_bouldin_score(data, labels)\n",
    "    bic = gmm.bic(data)\n",
    "    \n",
    "    metrics = {\n",
    "        'Silhouette Score': silhouette_avg,\n",
    "        'Davies-Bouldin Index': db_index,\n",
    "        'BIC': bic\n",
    "    }\n",
    "    \n",
    "    #print(f'Silhouette Score: {silhouette_avg}')\n",
    "    #print(f'Davies-Bouldin Index: {db_index}')\n",
    "    #print(f'Bayesian Information Criterion (BIC): {bic}')\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ddf8d589-30d7-4732-8632-7d8761ab3b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hierarchical_clustering(latent_representations, truth_labels, threshold=200, figsize=(20, 10), y_interval=50, p=10):\n",
    "    \"\"\"\n",
    "    Performs hierarchical clustering on the given latent representations, plots the dendrogram,\n",
    "    and returns the cluster labels along with performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - latent_representations: ndarray of shape (n_samples, n_features) The latent representations obtained from the Autoencoder.\n",
    "    - truth_labels: array-like of shape (n_samples,)  The true labels of the samples.\n",
    "    - threshold: float, optional (default=200)   The distance threshold for forming clusters.\n",
    "    - figsize: tuple, optional (default=(20, 10)) The size of the figure for plotting the dendrogram.\n",
    "    - y_interval: int, optional (default=50) The interval for y-axis ticks on the dendrogram.\n",
    "\n",
    "    Returns:\n",
    "    - cluster_labels: ndarray of shape (n_samples,) The cluster labels for each sample.\n",
    "    - ari: float The Adjusted Rand Index of the clustering.\n",
    "    - nmi: float The Normalized Mutual Information of the clustering.\n",
    "    \"\"\"\n",
    "    # Perform hierarchical clustering using Ward's method\n",
    "    linked = linkage(latent_representations, 'ward')\n",
    "\n",
    "    # Create and plot the dendrogram\n",
    "    plt.figure(figsize=figsize)\n",
    "    # Set custom y-axis intervals\n",
    "    max_d = np.max(linked[:, 2])\n",
    "    y_lim = max_d - (max_d/2)\n",
    "    \n",
    "    # Ensure y-ticks are within the range of the dendrogram\n",
    "    if max_d < y_interval:\n",
    "        y_ticks = np.arange(0, max_d + max_d/10, max_d/10)\n",
    "        \n",
    "    plt.yticks(np.arange(0, max_d + y_interval, y_interval))  # Adjust the interval as needed\n",
    "    dendrogram(linked, p=p, truncate_mode='level')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.ylim(0, y_lim)\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    # Add a horizontal line at the threshold\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "    # Get cluster labels based on the threshold\n",
    "    cluster_labels = fcluster(linked, threshold, criterion='distance')\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    ari = adjusted_rand_score(truth_labels, cluster_labels)\n",
    "    nmi = normalized_mutual_info_score(truth_labels, cluster_labels)\n",
    "\n",
    "    return linked, cluster_labels, ari, nmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc58324-db4b-4b70-96de-0d71d916eafb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# I. BUILD COHORT\n",
    "Build combined OSA and HF cohort with:\n",
    "\n",
    "subject_id, hadm_id, gender, race, age, BMI, admission type, Charlson Comorbidity Index score, length of stay, hospital expiration flag, and insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2aaa4de6-2b81-4e83-abec-bd876fc78f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "admissions = pd.read_csv(mimic4_path + 'hosp/admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "26737a5c-5baf-41ff-ba19-9cdbe52ab0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patients = pd.read_csv(mimic4_path + 'hosp/patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73aaf458-37a5-4e8f-9105-f520bb2c5371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dx_codes = pd.read_csv(mimic4_path + 'hosp/diagnoses_icd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfb5fd7c-b9e4-4546-8c8a-3781783cbc85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dx_description = pd.read_csv(mimic4_path + 'hosp/d_icd_diagnoses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ac3884b-3f4e-4fdf-ae07-ae2e3b7e21b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "omr = pd.read_csv(mimic4_path + 'hosp/omr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3679189b-7ff7-4ae5-b735-a5c9d3cf24b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "charlson = pd.read_csv('/global/cfs/projectdirs/m1532/Projects_MVP/Sophia/derived/charlson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6271cbbe-d0da-40f6-8c6c-7e06ea53d1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes = pd.read_csv('/global/cfs/projectdirs/m1532/Projects_MVP/_datasets/MIMIC_IV/physionet.org/files/mimic-iv-note/2.2/note/discharge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86166c-f8b3-424c-af1b-0b402606a5b3",
   "metadata": {},
   "source": [
    "## Obstructive sleep apnea (OSA)\n",
    "Extract admissions with OSA ICD diagnosis code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03d2c8ae-bef0-411f-8254-866bbe2bd5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_codes = pd.read_csv(root_path + 'icd_codes/osa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35f24779-88e9-4076-8e1e-5e827c7aac08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa = osa_codes.merge(dx_description, on ='icd_code', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4493f42c-dbd7-46ee-9444-e45a8fbee547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'osa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m osa \u001b[38;5;241m=\u001b[39m \u001b[43mosa\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(dx_codes, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micd_code\u001b[39m\u001b[38;5;124m'\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'osa' is not defined"
     ]
    }
   ],
   "source": [
    "osa = osa.merge(dx_codes, on='icd_code', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5641316a-f1aa-49ec-9a56-0d4e01342cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa = osa.merge(admissions, on = ['hadm_id', 'subject_id'] , how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a1e04f8-b8dd-4d36-847e-378450167365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa = osa[['subject_id', 'hadm_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c9aeba6-96cf-4e73-90a1-0120c863c8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa['osa'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a3b33d20-00de-4173-b34f-292db842335e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33005, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>osa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13340824</td>\n",
       "      <td>26708815</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002013</td>\n",
       "      <td>24848509</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002167</td>\n",
       "      <td>29383904</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002221</td>\n",
       "      <td>21008195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003019</td>\n",
       "      <td>20030125</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   osa\n",
       "0    13340824  26708815  True\n",
       "1    10002013  24848509  True\n",
       "2    10002167  29383904  True\n",
       "3    10002221  21008195  True\n",
       "4    10003019  20030125  True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(osa.shape)\n",
    "osa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "23d548a4-2edc-44b4-a99a-d907d8bf630f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa.drop_duplicates(subset = ['subject_id', 'hadm_id'], inplace = True)\n",
    "osa.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be44eb6f-9cfe-435f-9475-f935d89bf782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32974, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2a09d441-a5eb-42c0-a395-401ed8e5e957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14915"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osa['subject_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e66bac-7c58-4b80-b80f-81acc41c0308",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Heart failure (HF)\n",
    "Extract admissions with HF ICD diagnosis code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5b2a173-37f3-40fd-8f39-13daa7da5df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_codes = pd.read_csv(root_path + 'icd_codes/heart_failure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fa12e60d-dde3-478e-b817-c3c1e4aca9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf = hf_codes.merge(dx_description, on ='icd_code', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "79024f5c-e93d-4ff9-a45f-63ca4a33f320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf = hf.merge(dx_codes, on='icd_code', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f4ff6ae-9859-4625-800b-ecea6b55b723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf = hf.merge(admissions, on = ['hadm_id', 'subject_id'] , how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6cf4fd0-2379-4526-b2b5-2f845217f051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf = hf[['subject_id', 'hadm_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e5482e6-eb17-413f-b92b-d38c91f20cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf['hf'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2a2e2911-e486-45f6-bd03-61703a944510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53024, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>hf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10224335</td>\n",
       "      <td>28418370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10543835</td>\n",
       "      <td>20482351</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10624524</td>\n",
       "      <td>20456042</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11032631</td>\n",
       "      <td>25353318</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11034601</td>\n",
       "      <td>21104656</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id    hf\n",
       "0    10224335  28418370  True\n",
       "1    10543835  20482351  True\n",
       "2    10624524  20456042  True\n",
       "3    11032631  25353318  True\n",
       "4    11034601  21104656  True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hf.shape)\n",
    "hf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "811c67f4-8fa9-4031-9129-54bd250448a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf.drop_duplicates(subset = ['subject_id', 'hadm_id'], inplace = True)\n",
    "hf.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4fb9cd78-56a8-4a8e-a6d9-75d9bd98b0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21774"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf['subject_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f971438-9407-4075-b5a2-13712b29777f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## >=1 admission vs. >=2 admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1d710-9e7f-4019-87f4-ec800ceca0bd",
   "metadata": {},
   "source": [
    "### OSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb694a7e-042f-481c-afa8-a1234b0ee102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of patients with OSA:  14915\n",
      "Number of patients with OSA with ONLY 1 admission:  8952\n",
      "Number of patients with OSA with MORE THAN 1 admission:  5963\n"
     ]
    }
   ],
   "source": [
    "print(\"# of patients with OSA: \", osa['subject_id'].unique().size)\n",
    "print(\"Number of patients with OSA with ONLY 1 admission: \", osa.groupby(\"subject_id\").filter(lambda x: len(x) == 1).shape[0])\n",
    "\n",
    "osa_multiple_adm = osa.groupby(\"subject_id\").filter(lambda x: len(x) > 1).reset_index(drop=True)\n",
    "print(\"Number of patients with OSA with MORE THAN 1 admission: \", osa_multiple_adm['subject_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f3898f14-40e2-41b3-904a-b80e82c4c03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of OSA admissions where patient has >= 1 admission):  32974\n",
      "Total # of OSA admissions where patient has >= 2 admissions):  24022\n"
     ]
    }
   ],
   "source": [
    "print(\"Total # of OSA admissions where patient has >= 1 admission): \", osa['hadm_id'].unique().size)\n",
    "print(\"Total # of OSA admissions where patient has >= 2 admissions): \", osa_multiple_adm['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed80a4f-6503-42bc-8036-5f951e47cba0",
   "metadata": {},
   "source": [
    "### HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1167f6fc-a29d-4c29-bb13-4384ee0ce2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of patients with HF:  21774\n",
      "Number of patients with HF with ONLY 1 admission:  12296\n",
      "Number of patients with HF with MORE THAN 1 admission:  9478\n"
     ]
    }
   ],
   "source": [
    "print(\"# of patients with HF: \", hf['subject_id'].unique().size)\n",
    "print(\"Number of patients with HF with ONLY 1 admission: \", hf.groupby(\"subject_id\").filter(lambda x: len(x) == 1).shape[0])\n",
    "\n",
    "hf_multiple_adm = hf.groupby(\"subject_id\").filter(lambda x: len(x) > 1).reset_index(drop=True)\n",
    "print(\"Number of patients with HF with MORE THAN 1 admission: \", hf_multiple_adm['subject_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6fa22952-a317-4201-ae2d-36ce06247527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of HF admissions where patient has >= 1 admission):  53024\n",
      "Total # of HF admissions where patient has >= 2 admissions):  40728\n"
     ]
    }
   ],
   "source": [
    "print(\"Total # of HF admissions where patient has >= 1 admission): \", hf['hadm_id'].unique().size)\n",
    "print(\"Total # of HF admissions where patient has >= 2 admissions): \", hf_multiple_adm['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca918e-0415-4e5c-9051-e157e5f32fbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combined cohort (OSA and HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad49c92d-08ae-47e9-bbb8-6b22984616c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OSA and HF (1 or more admissions)\n",
    "cohort_osa_hf = osa.merge(hf, on =['hadm_id', 'subject_id'], how ='outer')\\\n",
    "    .fillna(value = False)\n",
    "cohort_osa_hf['group'] = cohort_osa_hf.apply(assign_group, axis=1)\n",
    "cohort_osa_hf['group_name'] = cohort_osa_hf['group'].apply(group_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dddd173d-1e1c-4731-93ed-4542dbf89a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OSA and HF (2 or more admissions)\n",
    "cohort_osa_hf_multiple_adm = osa_multiple_adm.merge(hf_multiple_adm, on =['hadm_id', 'subject_id'], how ='outer')\\\n",
    "    .fillna(value = False)\n",
    "cohort_osa_hf_multiple_adm['group'] = cohort_osa_hf_multiple_adm.apply(assign_group, axis=1)\n",
    "cohort_osa_hf_multiple_adm['group_name'] = cohort_osa_hf_multiple_adm['group'].apply(group_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e4f38e0-5fe8-482e-89d1-7e7551b6692e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort size for >= 1 admission (OSA/HF):  77493\n",
      "Cohort size for >= 2 admission (OSA/HF):  58218\n"
     ]
    }
   ],
   "source": [
    "print(\"Cohort size for >= 1 admission (OSA/HF): \", cohort_osa_hf.shape[0])\n",
    "print(\"Cohort size for >= 2 admission (OSA/HF): \", cohort_osa_hf_multiple_adm.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fa27e3c7-157e-489f-82e4-fe8748e21853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cohort_osa_hf.to_csv('Cohort/cohort_osa_hf.csv', index=False)\n",
    "# cohort_osa_hf_multiple_adm.to_csv('Cohort/cohort_osa_hf_multiple_adm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a558d39-342c-4dee-8cc1-658ea7fa3b5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ADD NOTES COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a5a65-9c0a-4342-bb37-a08dd8cf463d",
   "metadata": {},
   "source": [
    "### >= 1 admission   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9490cebf-2d01-42f2-9855-2182608e8bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes = cohort_osa_hf.merge(notes, on = ['hadm_id', 'subject_id'] , how ='inner')\n",
    "cohort_osa_hf_notes = cohort_osa_hf_notes[['subject_id', 'hadm_id', 'osa', 'hf', 'group', 'group_name', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275eceb-1e5d-4510-b85c-2e9ca40413c6",
   "metadata": {},
   "source": [
    "### >= 2 admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "59b08cbd-a8b7-4f8a-82e0-80321747e74c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_multiple_adm_notes = cohort_osa_hf_multiple_adm.merge(notes, on = ['hadm_id', 'subject_id'] , how ='inner')\n",
    "cohort_osa_hf_multiple_adm_notes = cohort_osa_hf_multiple_adm_notes[['subject_id', 'hadm_id', 'osa', 'hf', 'group', 'group_name', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9ebaf612-cba2-4e5c-a390-3092c0562d86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_name\n",
       "HF Only     41516\n",
       "OSA Only    21929\n",
       "OSA & HF     7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_osa_hf_notes.value_counts('group_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ce47698b-f3bf-4aab-a0b7-722b3cf2d04d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71408, 7)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_osa_hf_notes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e9ab0-3b70-45e7-8057-b5041550d508",
   "metadata": {},
   "source": [
    "<b>To CSV File</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbf123e0-2fb5-452e-b584-62fb517d7aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cohort_osa_hf_notes.to_csv('Cohort/cohort_osa_hf_notes.csv', index=False)\n",
    "# cohort_osa_hf_multiple_adm_notes.to_csv('Cohort/cohort_osa_hf_multiple_adm_notes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7349c21-406a-4af0-8115-507ec31f6338",
   "metadata": {
    "tags": []
   },
   "source": [
    "# II. ADD DEMOGRAPHIC FEATURES\n",
    "(mimiciv_hosp/admissions) <b>race, hospital expiration flag, insurance, length of stay, admission type</b>\n",
    "\n",
    "(mimiciv_hosp/omr) <b>BMI</b>\n",
    "\n",
    "(mimiciv_hosp/patients) <b>age, gender</b>\n",
    "\n",
    "(mimiciv_derived/charlson) <b>Charlson comorbidity index</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5794e34c-1b76-4482-a7b5-269edd26d9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If not read in already, uncomment\n",
    "\n",
    "# cohort_osa_hf_notes = pd.read_csv('cohort/cohort_osa_hf_notes.csv').reset_index(drop=True)\n",
    "# cohort_osa_hf_multiple_adm_notes = pd.read_csv('cohort/cohort_osa_hf_multiple_adm_notes.csv').reset_index(drop=True)\n",
    "\n",
    "# admissions = pd.read_csv(mimic4_path + 'hosp/admissions.csv')\n",
    "# omr = pdf.read_csv(mimic4_path + 'hosp/omr.csv')\n",
    "# patients = pd.read_csv(mimic4_path + 'hosp/patients.csv')\n",
    "# charlson = pd.read_csv('/global/cfs/projectdirs/m1532/Projects_MVP/Sophia/derived/charlson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "08f99186-bb7a-4df6-86ca-3682aa810c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>osa</th>\n",
       "      <th>hf</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13340824</td>\n",
       "      <td>26708815</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>OSA Only</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   osa     hf  group group_name  \\\n",
       "0    13340824  26708815  True  False      0   OSA Only   \n",
       "\n",
       "                                                text  \n",
       "0   \\nName:  ___                    Unit No:   __...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cohort_osa_hf_notes.shape[0])\n",
    "cohort_osa_hf_notes.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127299e1-b087-4379-a97c-8747ed621671",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge cohort with admissions table\n",
    "race, hospital expiration flag, insurance, length of stay, admission type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "57147646-009f-448f-8c01-f09125b36791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge cohort with admissions table\n",
    "cohort_osa_hf_notes_admissions = cohort_osa_hf_notes.merge(admissions,\n",
    "                                                           on=['subject_id', 'hadm_id'],\n",
    "                                                           how='inner').drop(['deathtime', 'admit_provider_id', \\\n",
    "                                                                              'admission_location', 'discharge_location', 'language', \\\n",
    "                                                                              'marital_status', 'edregtime', 'edouttime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ef96e6ba-ee37-49ec-b8cc-a82974116d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of admissions:  71408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>osa</th>\n",
       "      <th>hf</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>text</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>race</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13340824</td>\n",
       "      <td>26708815</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>OSA Only</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "      <td>2162-09-01 21:40:00</td>\n",
       "      <td>2162-09-07 17:15:00</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   osa     hf  group group_name  \\\n",
       "0    13340824  26708815  True  False      0   OSA Only   \n",
       "\n",
       "                                                text            admittime  \\\n",
       "0   \\nName:  ___                    Unit No:   __...  2162-09-01 21:40:00   \n",
       "\n",
       "             dischtime admission_type insurance   race  hospital_expire_flag  \n",
       "0  2162-09-07 17:15:00         URGENT  Medicare  WHITE                     0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"# of admissions: \", cohort_osa_hf_notes_admissions.shape[0])\n",
    "cohort_osa_hf_notes_admissions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6849a03d-4ab9-4152-80cf-bdb47df9b7cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### race classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6e50bbcf-cfdf-4b27-aad9-8f1e94852099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes_admissions['race_classified'] = cohort_osa_hf_notes_admissions['race'].apply(classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933a63c-0047-42ce-95e6-1f32ea02e383",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### calculate length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "22cea4b8-aa33-4729-a676-9b426c5b56ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/aidotse/tabular-data-generation/blob/main/preprocessing/LOS-real-dataset-preparation.ipynb\n",
    "\n",
    "# Convert admission and discharge times to datetime\n",
    "cohort_osa_hf_notes_admissions['admittime'] = pd.to_datetime(cohort_osa_hf_notes_admissions['admittime'])\n",
    "cohort_osa_hf_notes_admissions['dischtime'] = pd.to_datetime(cohort_osa_hf_notes_admissions['dischtime'])\n",
    "\n",
    "# Calculate length of stay using admittime and dischtime\n",
    "cohort_osa_hf_notes_admissions['los'] = (cohort_osa_hf_notes_admissions['dischtime'] - cohort_osa_hf_notes_admissions['admittime']).dt.total_seconds()/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6533355f-88e0-4d1f-bc0f-76c1337f7f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove extreme outliers (e.g., negative length of stay and value > 300)\n",
    "def outlier_quatile(df, col_name):\n",
    "    IQR = df[col_name].quantile(0.75) - df[col_name].quantile(0.25)\n",
    "    higher_bound = df[col_name].quantile(0.75) + (IQR * 3)\n",
    "    lower_bound = df[col_name].quantile(0.25) - (IQR * 3)\n",
    "    return higher_bound, lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8b7caf18-aa98-4a01-8d39-fdacf782e3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.880381944444444 -13.731250000000003\n",
      "Cohort size:  71408\n",
      "# of outlier LoS values:  2034\n"
     ]
    }
   ],
   "source": [
    "los_high, los_low = outlier_quatile(cohort_osa_hf_notes_admissions, 'los')\n",
    "print(los_high, los_low)\n",
    "\n",
    "print(\"Cohort size: \", cohort_osa_hf_notes_admissions.shape[0])\n",
    "print(\"# of outlier LoS values: \", cohort_osa_hf_notes_admissions[((cohort_osa_hf_notes_admissions['los'] < 0) | (cohort_osa_hf_notes_admissions['los'] > los_high))].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "09f4c2c1-645b-4254-a6bc-541730d6337b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes_admissions = cohort_osa_hf_notes_admissions[((cohort_osa_hf_notes_admissions['los'] > 0) &\\\n",
    "                                                                 (cohort_osa_hf_notes_admissions['los'] < los_high))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4af99da7-6875-41f4-b581-22f29f998562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69374\n"
     ]
    }
   ],
   "source": [
    "print(cohort_osa_hf_notes_admissions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe5bfd-284d-4a37-b078-3bfe2ddea728",
   "metadata": {},
   "source": [
    "## Merge cohort with patients table\n",
    "age, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cdb6e391-e144-4633-b401-e4e4114eb1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes_admissions_patients = cohort_osa_hf_notes_admissions.merge(patients, on='subject_id', how='inner').drop(['anchor_year_group', 'dod', 'race'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2f54100d-7b0a-457d-9cfd-34b4dca044c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of admissions:  69374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>osa</th>\n",
       "      <th>hf</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>text</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>race_classified</th>\n",
       "      <th>los</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13340824</td>\n",
       "      <td>26708815</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>OSA Only</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "      <td>2162-09-01 21:40:00</td>\n",
       "      <td>2162-09-07 17:15:00</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>5.815972</td>\n",
       "      <td>F</td>\n",
       "      <td>91</td>\n",
       "      <td>2162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   osa     hf  group group_name  \\\n",
       "0    13340824  26708815  True  False      0   OSA Only   \n",
       "\n",
       "                                                text           admittime  \\\n",
       "0   \\nName:  ___                    Unit No:   __... 2162-09-01 21:40:00   \n",
       "\n",
       "            dischtime admission_type insurance  hospital_expire_flag  \\\n",
       "0 2162-09-07 17:15:00         URGENT  Medicare                     0   \n",
       "\n",
       "  race_classified       los gender  anchor_age  anchor_year  \n",
       "0               W  5.815972      F          91         2162  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of admissions: \", cohort_osa_hf_notes_admissions_patients.shape[0])\n",
    "cohort_osa_hf_notes_admissions_patients.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810ed42-51c7-44be-ab5e-dea0ee3f4ca7",
   "metadata": {},
   "source": [
    "#### calculate age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "14b21a0b-ab90-462d-9513-2e0846ba61b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert admission year to datetime\n",
    "cohort_osa_hf_notes_admissions_patients['admittime_year'] = pd.DatetimeIndex(cohort_osa_hf_notes_admissions_patients['admittime']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a895d56-e516-45ee-8230-c24b015f3403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the age of a patient = hospital admission time - anchor_year + anchor_age\n",
    "cohort_osa_hf_notes_admissions_patients['age'] = cohort_osa_hf_notes_admissions_patients['admittime_year'] - cohort_osa_hf_notes_admissions_patients['anchor_year'] + cohort_osa_hf_notes_admissions_patients['anchor_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d17dc-79a0-48d1-8c53-3d5a5180444a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge cohort with charlson table\n",
    "Charlson comorbidity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "29ab244e-8819-4d07-b354-78e9d30872a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "charlson_filtered = charlson[['subject_id', 'hadm_id', 'charlson_comorbidity_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a4fa501-b71f-43d4-998a-0f1c19d6a618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes_admissions_patients_charlson = cohort_osa_hf_notes_admissions_patients.merge(charlson_filtered, on=['subject_id', 'hadm_id'], how='inner')\\\n",
    "    .drop(['anchor_age', 'anchor_year', 'admittime_year', 'admittime', 'dischtime'], axis=1)\\\n",
    "    .rename(columns={'charlson_comorbidity_index':'charlson'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1bd9a57e-8471-4a6d-91a4-db7df82e8053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of admissions:  69374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>osa</th>\n",
       "      <th>hf</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>text</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>race_classified</th>\n",
       "      <th>los</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>charlson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13340824</td>\n",
       "      <td>26708815</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>OSA Only</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>5.815972</td>\n",
       "      <td>F</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   osa     hf  group group_name  \\\n",
       "0    13340824  26708815  True  False      0   OSA Only   \n",
       "\n",
       "                                                text admission_type insurance  \\\n",
       "0   \\nName:  ___                    Unit No:   __...         URGENT  Medicare   \n",
       "\n",
       "   hospital_expire_flag race_classified       los gender  age  charlson  \n",
       "0                     0               W  5.815972      F   91         4  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of admissions: \", cohort_osa_hf_notes_admissions_patients_charlson.shape[0])\n",
    "cohort_osa_hf_notes_admissions_patients_charlson.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7c1a0-a3e5-4c24-8d31-9c51ec885532",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge cohort with OMR table\n",
    "BMI (patient level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1d0fd8be-0082-4fd1-9885-b069d7093951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_bmi = cohort_osa_hf_notes_admissions_patients_charlson\\\n",
    "    .merge(omr[['subject_id', 'result_name', 'result_value']], on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d914439d-c779-4d46-89eb-af719c5cc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract rows that have BMI recorded\n",
    "add_bmi = add_bmi[add_bmi['result_name'].str.contains(\"BMI\")]\n",
    "add_bmi['result_value'] = add_bmi['result_value'].astype(float)\n",
    "add_bmi = add_bmi.rename(columns={'result_value': 'bmi'})\\\n",
    "    .drop('result_name', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "75a76670-577a-4372-bcde-925629cc105e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since BMI is on patient level, get median value from all admissions per patient\n",
    "cohort_osa_hf_notes_admissions_patients_charlson_bmi = add_bmi\\\n",
    "    .groupby(['subject_id', 'hadm_id'])['bmi'].median().reset_index()\\\n",
    "    .merge(add_bmi.drop('bmi', axis='columns'), on=['subject_id', 'hadm_id'])\\\n",
    "    .drop_duplicates(subset=['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5f82f729-e71b-4094-b10b-cb1217eda5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>bmi</th>\n",
       "      <th>osa</th>\n",
       "      <th>hf</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>text</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>race_classified</th>\n",
       "      <th>los</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>charlson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000980</td>\n",
       "      <td>20897796</td>\n",
       "      <td>31.6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>2.587500</td>\n",
       "      <td>F</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10000980</td>\n",
       "      <td>24947999</td>\n",
       "      <td>31.6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.792361</td>\n",
       "      <td>F</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>31.6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>7.897917</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id   hadm_id   bmi    osa    hf  group group_name  \\\n",
       "0      10000980  20897796  31.6  False  True      2    HF Only   \n",
       "73     10000980  24947999  31.6  False  True      2    HF Only   \n",
       "146    10000980  25242409  31.6  False  True      2    HF Only   \n",
       "\n",
       "                                                  text     admission_type  \\\n",
       "0     \\nName:  ___          Unit No:   ___\\n \\nAdmi...  OBSERVATION ADMIT   \n",
       "73    \\nName:  ___          Unit No:   ___\\n \\nAdmi...           EW EMER.   \n",
       "146   \\nName:  ___          Unit No:   ___\\n \\nAdmi...           EW EMER.   \n",
       "\n",
       "    insurance  hospital_expire_flag race_classified       los gender  age  \\\n",
       "0       Other                     0               B  2.587500      F   80   \n",
       "73   Medicare                     0               B  1.792361      F   77   \n",
       "146  Medicare                     0               B  7.897917      F   78   \n",
       "\n",
       "     charlson  \n",
       "0           9  \n",
       "73          9  \n",
       "146        10  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_osa_hf_notes_admissions_patients_charlson_bmi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "efa0e6d8-b42b-439b-812f-3030039f27a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort size after adding BMI data:  54220\n"
     ]
    }
   ],
   "source": [
    "print(\"Cohort size after adding BMI data: \", cohort_osa_hf_notes_admissions_patients_charlson_bmi.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d01c09-53e9-49bf-b9b9-25c0d7e42f2a",
   "metadata": {},
   "source": [
    "<b>Remove outliers</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "97000e30-f7e4-47f6-9a85-94b245bfc5d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of abnormal BMI values:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"# of abnormal BMI values: \", \\\n",
    "      cohort_osa_hf_notes_admissions_patients_charlson_bmi\\\n",
    "      [((cohort_osa_hf_notes_admissions_patients_charlson_bmi['bmi'] < 1) |\\\n",
    "        (cohort_osa_hf_notes_admissions_patients_charlson_bmi['bmi'] > 250))]\\\n",
    "      .shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "491b7747-81dd-45a1-a814-1164ab87f10c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmi\n",
       "0.40       1\n",
       "0.80       2\n",
       "2.15       2\n",
       "2.45       1\n",
       "4.70       2\n",
       "          ..\n",
       "2250.00    2\n",
       "3093.20    1\n",
       "4554.70    1\n",
       "4881.90    3\n",
       "6102.00    3\n",
       "Name: count, Length: 1265, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_osa_hf_notes_admissions_patients_charlson_bmi.value_counts('bmi').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "358b0498-fe40-4488-9751-e93ec7dd3801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes_admissions_patients_charlson_bmi_cleaned = cohort_osa_hf_notes_admissions_patients_charlson_bmi\\\n",
    "    [((cohort_osa_hf_notes_admissions_patients_charlson_bmi['bmi'] > 1) &\\\n",
    "      (cohort_osa_hf_notes_admissions_patients_charlson_bmi['bmi'] < 250))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "95d4b260-c2ec-45c9-a48a-1e40d3d64c32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort size after removing outlier BMI values:  54204\n"
     ]
    }
   ],
   "source": [
    "print(\"Cohort size after removing outlier BMI values: \", cohort_osa_hf_notes_admissions_patients_charlson_bmi_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3cde6b53-a511-43af-8b7f-abddb838a27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort_osa_hf_notes_admissions_patients_charlson_bmi_cleaned.to_csv(root_path + 'Cohort/cohort_osa_hf_notes_admissions_patients_charlson_bmi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6cc53-8e49-4abf-9a50-fec8d0cb350d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# III. ADD LABEVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d54a95-6c24-419d-aa60-2ce8b06a4b61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge labevents tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "56cc209c-8da2-43eb-9561-2eabc63fab0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_m1 = pd.read_csv(root_path + 'Cohort/cohort_osa_hf_notes_admissions_patients_charlson_bmi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "10dfd3e9-f51e-435b-b2fb-5fefe91df829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>bmi</th>\n",
       "      <th>osa</th>\n",
       "      <th>hf</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>text</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>race_classified</th>\n",
       "      <th>los</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>charlson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000980</td>\n",
       "      <td>20897796</td>\n",
       "      <td>31.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>2.587500</td>\n",
       "      <td>F</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980</td>\n",
       "      <td>24947999</td>\n",
       "      <td>31.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.792361</td>\n",
       "      <td>F</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25242409</td>\n",
       "      <td>31.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>7.897917</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000980</td>\n",
       "      <td>26913865</td>\n",
       "      <td>31.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>5.806944</td>\n",
       "      <td>F</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000980</td>\n",
       "      <td>29654838</td>\n",
       "      <td>31.60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.992361</td>\n",
       "      <td>F</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>19998330</td>\n",
       "      <td>24096838</td>\n",
       "      <td>25.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>OSA &amp; HF</td>\n",
       "      <td>\\nName:  ___                        Unit No: ...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>3.804861</td>\n",
       "      <td>F</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54200</th>\n",
       "      <td>19998330</td>\n",
       "      <td>24492004</td>\n",
       "      <td>25.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>OSA &amp; HF</td>\n",
       "      <td>\\nName:  ___                        Unit No: ...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>7.425000</td>\n",
       "      <td>F</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54201</th>\n",
       "      <td>19998330</td>\n",
       "      <td>27282608</td>\n",
       "      <td>25.00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>OSA &amp; HF</td>\n",
       "      <td>\\nName:  ___                        Unit No: ...</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.397917</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54202</th>\n",
       "      <td>19998350</td>\n",
       "      <td>21130518</td>\n",
       "      <td>41.65</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>OSA Only</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "      <td>EU OBSERVATION</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.875694</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54203</th>\n",
       "      <td>19998350</td>\n",
       "      <td>27108332</td>\n",
       "      <td>41.65</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>OSA Only</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "      <td>EU OBSERVATION</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.307639</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54204 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id   hadm_id    bmi    osa     hf  group group_name  \\\n",
       "0        10000980  20897796  31.60  False   True      2    HF Only   \n",
       "1        10000980  24947999  31.60  False   True      2    HF Only   \n",
       "2        10000980  25242409  31.60  False   True      2    HF Only   \n",
       "3        10000980  26913865  31.60  False   True      2    HF Only   \n",
       "4        10000980  29654838  31.60  False   True      2    HF Only   \n",
       "...           ...       ...    ...    ...    ...    ...        ...   \n",
       "54199    19998330  24096838  25.00   True   True      1   OSA & HF   \n",
       "54200    19998330  24492004  25.00   True   True      1   OSA & HF   \n",
       "54201    19998330  27282608  25.00   True   True      1   OSA & HF   \n",
       "54202    19998350  21130518  41.65   True  False      0   OSA Only   \n",
       "54203    19998350  27108332  41.65   True  False      0   OSA Only   \n",
       "\n",
       "                                                    text     admission_type  \\\n",
       "0       \\nName:  ___          Unit No:   ___\\n \\nAdmi...  OBSERVATION ADMIT   \n",
       "1       \\nName:  ___          Unit No:   ___\\n \\nAdmi...           EW EMER.   \n",
       "2       \\nName:  ___          Unit No:   ___\\n \\nAdmi...           EW EMER.   \n",
       "3       \\nName:  ___          Unit No:   ___\\n \\nAdmi...           EW EMER.   \n",
       "4       \\nName:  ___          Unit No:   ___\\n \\nAdmi...           EW EMER.   \n",
       "...                                                  ...                ...   \n",
       "54199   \\nName:  ___                        Unit No: ...           EW EMER.   \n",
       "54200   \\nName:  ___                        Unit No: ...           EW EMER.   \n",
       "54201   \\nName:  ___                        Unit No: ...           EW EMER.   \n",
       "54202   \\nName:  ___                 Unit No:   ___\\n...     EU OBSERVATION   \n",
       "54203   \\nName:  ___                 Unit No:   ___\\n...     EU OBSERVATION   \n",
       "\n",
       "      insurance  hospital_expire_flag race_classified       los gender  age  \\\n",
       "0         Other                     0               B  2.587500      F   80   \n",
       "1      Medicare                     0               B  1.792361      F   77   \n",
       "2      Medicare                     0               B  7.897917      F   78   \n",
       "3      Medicare                     0               B  5.806944      F   76   \n",
       "4      Medicare                     0               B  1.992361      F   75   \n",
       "...         ...                   ...             ...       ...    ...  ...   \n",
       "54199     Other                     0               B  3.804861      F   72   \n",
       "54200     Other                     0               B  7.425000      F   72   \n",
       "54201  Medicare                     0               B  1.397917      F   71   \n",
       "54202     Other                     0               B  0.875694      M   56   \n",
       "54203  Medicare                     0               B  1.307639      M   53   \n",
       "\n",
       "       charlson  \n",
       "0             9  \n",
       "1             9  \n",
       "2            10  \n",
       "3             8  \n",
       "4             8  \n",
       "...         ...  \n",
       "54199         8  \n",
       "54200         8  \n",
       "54201         8  \n",
       "54202         4  \n",
       "54203         3  \n",
       "\n",
       "[54204 rows x 16 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osa_hf_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fb057f7b-5013-4c74-9469-aac00b8b9ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['itemid', 'label', 'fluid', 'category'], dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_labitems = pd.read_csv(mimic4_path + 'hosp/d_labitems.csv')\n",
    "print(d_labitems.shape)\n",
    "d_labitems.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba276f4-9853-4c8e-8ea4-6ff64b5c8bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labevents = pd.read_csv(mimic4_path + 'hosp/labevents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d7bb7-99fb-4b93-be4b-64dfa6cde18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(labevents.shape)\n",
    "labevents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc5ce-62cf-4d49-bc85-1d14b9a80b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using cleaned cohort (without patients that have negative/outlier LOS)\n",
    "osa_hf_labevents = osa_hf_m1.merge(labevents, how = 'inner', on = ['subject_id', 'hadm_id'])\n",
    "osa_hf_labevents = osa_hf_labevents.merge(d_labitems, how = 'inner', on = 'itemid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2053ed2-ccc3-4d80-9040-b2f71f8c7295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_labevents = osa_hf_labevents[['itemid', 'label']].drop_duplicates(subset='itemid')\n",
    "labels_labevents = pd.Series(labels_labevents['label'].values,index=labels_labevents['itemid'].apply(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecdc85-3e51-4a67-9eb2-2570d582d955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_labevents.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5497f-bcdf-49e1-9121-01a772150689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels_labevents.to_csv(root_path + 'Data/labels_labevents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105cc43-e4ba-4313-aec0-abb08daba4ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Keep labevents that are recorded in more than a certain % of admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215c98b-b0e6-412a-9bac-066a7ab3d87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labevents_unique = osa_hf_labevents['itemid'].unique()\n",
    "labevents_unique.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f437373-1dbc-4395-ad97-9e3481f2e03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"# of admissions in original, cleaned cohort: \", osa_hf_m1['hadm_id'].unique().size)\n",
    "print(\"# of admissions after merging with labevents: \", osa_hf_labevents['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6c76a-2a89-42c9-bdb3-c6fa7985dbd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### calculate percentage of patients for each lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf998737-1089-4863-a436-6a003835cb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_itemid = osa_hf_labevents['itemid'].unique()\n",
    "print(\"# of unique itemid: \", unique_itemid.size) # Note: Some itemids share lab name with another itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82ec65-3f5b-4d99-9e03-dd5986d3dcad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For each lab, calculate percentage of patients that have the lab recorded\n",
    "itemid_percentage_list = []\n",
    "for itemid in tqdm(unique_itemid):\n",
    "    itemid_rows = osa_hf_labevents[osa_hf_labevents['itemid'] == itemid]\n",
    "    percentage = itemid_rows['hadm_id'].unique().size / osa_hf_labevents['hadm_id'].unique().size * 100\n",
    "    itemid_percentage_list.append([itemid, percentage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d97192-d6c5-4e4c-8dd0-0cf6a1fc4dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert list to DataFrame\n",
    "itemid_percentage_df = pd.DataFrame(itemid_percentage_list, columns=[\"itemid\", \"percentage\"])\n",
    "itemid_percentage_df.sort_values(by=[\"percentage\"], ascending=False, ignore_index=True, inplace=True)\n",
    "print(\"Lowest percentages: \")\n",
    "itemid_percentage_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef9b66-2ab1-4c66-8acd-7f95a1671d78",
   "metadata": {},
   "source": [
    "<b>To CSV file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4c062-5a4a-4c8f-aa0a-17d5c0c39e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# itemid_percentage_df.to_csv(root_path + 'Data/common_labevents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7345f-360f-4e48-be64-622024d3303c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 0.5 # customized percentage\n",
    "value = itemid_percentage_df[itemid_percentage_df[\"percentage\"] > n].shape[0]\n",
    "print(f\"Number of itemid in > {n} % of admissions: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63b34b-11c3-4291-bac9-48386616b558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If doing cutoff percentage value\n",
    "itemid_keep = itemid_percentage_df[itemid_percentage_df[\"percentage\"] > n]\n",
    "mask = osa_hf_labevents['itemid'].isin(list(itemid_keep['itemid']))\n",
    "osa_hf_labevents_cleaned = osa_hf_labevents[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d5a2e-88ef-42eb-ae37-b00b984a123c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_cleaned['itemid'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b622690-4e1f-4d3d-be98-9a4769acfb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49a8a2-2452-4525-88bd-a6f4c62a02a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_m1.shape[0])\n",
    "print(osa_hf_labevents_cleaned['hadm_id'].unique().size)\n",
    "osa_hf_labevents_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582a587-8a49-4081-beed-a0fabb40a0e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing\n",
    "for each lab (admission-level), get count of abnormal value recordings\n",
    "\n",
    "<i>Note: Some hadm_id disappear due to NaN value in ref_range_lower and/or ref_range_upper.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0755e-209c-4931-bced-420633f337b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab_values = osa_hf_labevents_cleaned.groupby(['subject_id', 'hadm_id','itemid','ref_range_lower','ref_range_upper'])['valuenum'].median()\n",
    "lab_values = lab_values.reset_index(name='valuenum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc850dd-65ba-4539-9514-be7aa852a062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(lab_values['hadm_id'].unique().size)\n",
    "lab_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858d4f0-0fac-4980-9c40-b64dc753665c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trace why some hadm_id disappear\n",
    "# Some hadm_id disappear due to NaN value in ref_range_lower and/or ref_range_upper.\n",
    "test = osa_hf_labevents_cleaned[~osa_hf_labevents_cleaned['hadm_id'].isin(list(lab_values['hadm_id']))]\n",
    "print(test['hadm_id'].unique().size)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae26931-6890-4931-8d50-77753e48f2a1",
   "metadata": {},
   "source": [
    "### without flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa897e4-5cfe-41e1-920e-4902ed29b32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab_values = osa_hf_labevents_cleaned.groupby(['subject_id', 'hadm_id','itemid','ref_range_lower','ref_range_upper'])['valuenum'].median()\n",
    "lab_values = lab_values.reset_index(name='valuenum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013f459-09d8-43cc-9c87-7b771ea3611e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(lab_values['hadm_id'].unique().size)\n",
    "lab_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db5f2a-7dd0-45e0-be23-562df97ee616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trace why some hadm_id disappear\n",
    "# Some hadm_id disappear due to NaN value in ref_range_lower and/or ref_range_upper.\n",
    "test = osa_hf_labevents_cleaned[~osa_hf_labevents_cleaned['hadm_id'].isin(list(lab_values['hadm_id']))]\n",
    "print(test['hadm_id'].unique().size)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b12847-3ef8-47ea-a140-5ddae2b22f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rows where lab values are outside normal range\n",
    "osa_hf_labevents_cleaned_abnormal_values = lab_values[(lab_values['valuenum'] < lab_values['ref_range_lower']) \\\n",
    "                                                      | (lab_values['valuenum'] > lab_values['ref_range_upper'])].drop(['ref_range_lower', 'ref_range_upper'], axis='columns')\n",
    "osa_hf_labevents_cleaned_abnormal_values.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41843a3-79b2-4833-8f63-d426cf45ec68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_cleaned_abnormal_values_count = osa_hf_labevents_cleaned_abnormal_values.groupby(['subject_id', 'hadm_id','itemid'])['valuenum'].count()\n",
    "osa_hf_labevents_cleaned_abnormal_values_count_df = osa_hf_labevents_cleaned_abnormal_values_count.reset_index(name='count')\n",
    "\n",
    "print(osa_hf_labevents_cleaned_abnormal_values_count_df.shape[0])\n",
    "osa_hf_labevents_cleaned_abnormal_values_count_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de5df3-ccda-422b-a22d-ccf6e7b7ee65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_cleaned_abnormal_values_count_df[osa_hf_labevents_cleaned_abnormal_values_count_df['count'] >= 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbf1d7-c71c-4765-a155-7acf22440bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pivot DataFrame -> itemid as columns\n",
    "df_pivot = osa_hf_labevents_cleaned_abnormal_values_count_df\\\n",
    "    .pivot(index=['subject_id', 'hadm_id'], columns=['itemid'], values='count')\n",
    "\n",
    "# Keep all rows, regardless if they have an abnormal value recorded\n",
    "osa_hf_labevents_cleaned_abnormal_values_count_df_pivot = df_pivot\\\n",
    "    .rename_axis(columns=None)\\\n",
    "    .reset_index()\n",
    "\n",
    "osa_hf_labevents_cleaned_abnormal_values_count_df_pivot = osa_hf_labevents_cleaned_abnormal_values_count_df_pivot\\\n",
    "    .merge(lab_values[['subject_id', 'hadm_id']].drop_duplicates(subset=['subject_id', 'hadm_id']), on=['subject_id', 'hadm_id'], how='outer', validate=\"1:1\")\\\n",
    "    .fillna(0)\\\n",
    "    .astype(int)\n",
    "\n",
    "print(osa_hf_labevents_cleaned_abnormal_values_count_df_pivot.shape)\n",
    "osa_hf_labevents_cleaned_abnormal_values_count_df_pivot.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f71424-c62a-4126-9df6-62e393b1aa19",
   "metadata": {},
   "source": [
    "### with flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f899507-caf8-4e04-b486-97540f8933d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab_values_flag = osa_hf_labevents_cleaned[['subject_id', 'hadm_id','itemid','flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c073d6-2f8d-45ab-9345-3a322db2584e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rows where lab values are outside normal range\n",
    "osa_hf_labevents_cleaned_abnormal_flag = lab_values_flag[lab_values_flag['flag'] == 'abnormal']\n",
    "osa_hf_labevents_cleaned_abnormal_flag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aaf7f9-a7a2-4eb0-a119-fd059a8b32a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_cleaned_abnormal_flag_count = osa_hf_labevents_cleaned_abnormal_flag.groupby(['subject_id', 'hadm_id','itemid'])['flag'].count()\n",
    "osa_hf_labevents_cleaned_abnormal_flag_count_df = osa_hf_labevents_cleaned_abnormal_flag_count.reset_index(name='count')\n",
    "\n",
    "print(osa_hf_labevents_cleaned_abnormal_flag_count_df.shape[0])\n",
    "osa_hf_labevents_cleaned_abnormal_flag_count_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825c4c8-6dbe-4074-bcbf-c705a1b9c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_labevents_cleaned_abnormal_flag_count_df.value_counts('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3681258-66aa-4966-b182-7522e77e56a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pivot DataFrame -> itemid as columns ?? 3rd section review later\n",
    "df_pivot = osa_hf_labevents_cleaned_abnormal_flag_count_df\\\n",
    "    .pivot(index=['subject_id', 'hadm_id'], columns=['itemid'], values='count')\n",
    "\n",
    "# Keep all rows, regardless if they have an abnormal value recorded\n",
    "osa_hf_labevents_cleaned_abnormal_flag_count_df_pivot = df_pivot\\\n",
    "    .rename_axis(columns=None)\\\n",
    "    .reset_index()\n",
    "\n",
    "osa_hf_labevents_cleaned_abnormal_flag_count_df_pivot = osa_hf_labevents_cleaned_abnormal_flag_count_df_pivot\\\n",
    "    .merge(lab_values[['subject_id', 'hadm_id']].drop_duplicates(subset=['subject_id', 'hadm_id']), on=['subject_id', 'hadm_id'], how='outer', validate=\"1:1\")\\\n",
    "    .fillna(0)\\\n",
    "    .astype(int)\n",
    "\n",
    "print(osa_hf_labevents_cleaned_abnormal_flag_count_df_pivot.shape)\n",
    "osa_hf_labevents_cleaned_abnormal_flag_count_df_pivot.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0667f-6973-430b-a3c0-aa991c6f6ad3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### merge with original cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf4f08-ab72-44a0-9ec9-af1e92435349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_labevents_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca6814-ff74-40ee-942e-b0ffc3dbfb94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_abnormal_count = osa_hf_labevents_cleaned.loc[:, 'subject_id':'charlson']\\\n",
    "    .drop_duplicates(subset=['subject_id', 'hadm_id'])\\\n",
    "    .merge(osa_hf_labevents_cleaned_abnormal_flag_count_df_pivot, on=['subject_id', 'hadm_id'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194e4c9-186b-420d-af62-b9c8bdc0a1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_labevents_abnormal_count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66779d7-8100-4a91-902a-179e12b7ed49",
   "metadata": {
    "tags": []
   },
   "source": [
    "<b>To CSV file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dce401-c9c9-47ea-997c-2c0db7e546c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_labevents_abnormal_count.to_csv(root_path + 'Cohort/osa_hf_labevents_abnormal_count_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3732c08-fc7d-46b8-9624-1c0df005793a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IV. ADD DIAGNOSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2e55d-d853-4db0-b1ad-be5658030389",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merge diagnosis table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af50c08-d483-4c82-9c98-9799b9242634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_m1 = pd.read_csv(root_path + 'Cohort/cohort_osa_hf_notes_admissions_patients_charlson_bmi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0b2bb-7fed-488d-a6b5-7af9e3f10040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_m1.shape)\n",
    "print(osa_hf_m1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d19b5d-c9ac-477e-a26e-68f1ecaa0407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_icd_diagnoses = pd.read_csv(mimic4_path + 'hosp/d_icd_diagnoses.csv')\n",
    "print(d_icd_diagnoses.shape)\n",
    "d_icd_diagnoses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dae70a-343a-4cea-8bd0-2c0cb219739f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diagnoses = pd.read_csv(mimic4_path + 'hosp/diagnoses_icd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4345a-cf32-4ae4-82e0-403943ab4ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(diagnoses.shape)\n",
    "diagnoses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8bb4a-d070-4b55-b84d-e12e502ca054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using cleaned cohort (without patients that have negative/outlier LOS)\n",
    "osa_hf_diagnoses_1 = osa_hf_m1.merge(diagnoses, how = 'inner', on = ['subject_id', 'hadm_id'])\n",
    "osa_hf_diagnoses = osa_hf_diagnoses_1.merge(d_icd_diagnoses, how = 'inner', on = ['icd_code', 'icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3060c-9754-4fc0-afbc-44e3046e914c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_codes = pd.read_csv(root_path + 'icd_codes/osa.csv')\n",
    "hf_codes = pd.read_csv(root_path + 'icd_codes/heart_failure.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a3be6-525d-4782-a2f9-01be2f7015f0",
   "metadata": {},
   "source": [
    "## Clean diagnosis file\n",
    "Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e631b5e-92a1-4617-80da-8b8ece53064a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_code_list = list(osa_codes['icd_code'].astype(str))\n",
    "osa_code_list = [re.sub(r'\\xa0$', '', code) for code in osa_code_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95442c5a-0959-4682-af47-e71033e9e531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(list(osa_codes['icd_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ba413-3272-4ae5-acbc-b12076e69e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_code_list = list(hf_codes['icd_code'].astype(str))\n",
    "hf_code_list = [re.sub(r'\\xa0$', '', code) for code in hf_code_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a6da9-6e22-4207-994f-bb03efa1a1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(hf_code_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e8d50-e968-4915-ade3-23defbb8e63c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove rows with OSA and HF ICD diagnosis codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac1cbc-b173-445c-b1ea-8504a6353cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove diagnoses for OSA and HF\n",
    "mask = (osa_hf_diagnoses['icd_code'].isin(osa_code_list)) | (osa_hf_diagnoses['icd_code'].isin(hf_code_list))\n",
    "diagnoses_updated = osa_hf_diagnoses[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66acab-3300-45f0-9396-ae02dcd43500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Original cohort shape: \", osa_hf_m1.shape)\n",
    "print(\"Diagnoses before filtering shape: \", osa_hf_diagnoses.shape)\n",
    "print(\"Filtered diagnoses shape: \", diagnoses_updated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7d3d1-f7ab-495b-8c31-d280b8368ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"# of ICD codes before removing OSA and HF codes: \", osa_hf_diagnoses['icd_code'].unique().size)\n",
    "print(\"# of ICD Codes after removing OSA and HF codes: \", diagnoses_updated['icd_code'].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a886c-0174-4a3e-80f3-facf131e6fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Keep ICD codes that are recorded in more than a certain % of admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce52e55-e430-4d02-b5b5-eed50f919dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_osa_only = diagnoses_updated[diagnoses_updated['group'] == 0]\n",
    "icd_code_hf_only = diagnoses_updated[diagnoses_updated['group'] == 2]\n",
    "icd_code_osa_hf = diagnoses_updated[diagnoses_updated['group'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4251b9-f2a6-49a0-8b38-cd87d5a43473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_icd_code_osa = icd_code_osa_only['icd_code'].unique()\n",
    "unique_icd_code_hf = icd_code_hf_only['icd_code'].unique()\n",
    "unique_icd_code_osa_hf = icd_code_osa_hf['icd_code'].unique()\n",
    "\n",
    "print(\"# of unique ICD codes in OSA only cohort: \", unique_icd_code_osa.size)\n",
    "print(\"# of unique ICD codes in HF only cohort: \", unique_icd_code_hf.size)\n",
    "print(\"# of unique ICD codes in OSA + HF cohort: \", unique_icd_code_osa_hf.size)\n",
    "# test = unique_icd_code_osa[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78472c6b-298e-4fe6-a9da-b0b7217fd432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_icd_codes = diagnoses_updated['icd_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5fec8-db16-4f62-8f17-4b620bf55054",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For each ICD code, calculate percentage of admissions that have the ICD code recorded\n",
    "Note: takes a while to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168c936-bdd3-4bb4-bb65-cfcbaee0ba6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### most common ICD codes for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4fc06-d66e-4829-9b91-7512eb814a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_list_osa = []\n",
    "for icd_code in tqdm(unique_icd_code_osa):\n",
    "    icd_code_rows = icd_code_osa_only[icd_code_osa_only['icd_code'] == icd_code]\n",
    "    percentage = icd_code_rows['hadm_id'].unique().size / icd_code_osa_only['hadm_id'].unique().size * 100\n",
    "    if percentage > 0.001:\n",
    "        icd_code_percentage_list_osa.append([icd_code, percentage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af1a04-eda8-42b8-9948-538572f29e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_list_hf = []\n",
    "for icd_code in tqdm(unique_icd_code_hf):\n",
    "    icd_code_rows = icd_code_hf_only[icd_code_hf_only['icd_code'] == icd_code]\n",
    "    percentage = icd_code_rows['hadm_id'].unique().size / icd_code_hf_only['hadm_id'].unique().size * 100\n",
    "    icd_code_percentage_list_hf.append([icd_code, percentage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1720e31-03df-4502-bde3-8b92c8a870bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_list_osa_hf = []\n",
    "for icd_code in tqdm(unique_icd_code_osa_hf):\n",
    "    icd_code_rows = icd_code_osa_hf[icd_code_osa_hf['icd_code'] == icd_code]\n",
    "    percentage = icd_code_rows['hadm_id'].unique().size / icd_code_osa_hf['hadm_id'].unique().size * 100\n",
    "    icd_code_percentage_list_osa_hf.append([icd_code, percentage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ae5c5-3321-4092-9db3-1cec84ae975f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert list to DataFrame\n",
    "osa_common_icd_codes = pd.DataFrame(icd_code_percentage_list_osa, columns=[\"icd_code\", \"percentage\"]).sort_values(by=[\"percentage\"], ascending=False, ignore_index=True)\n",
    "hf_common_icd_codes = pd.DataFrame(icd_code_percentage_list_hf, columns=[\"icd_code\", \"percentage\"]).sort_values(by=[\"percentage\"], ascending=False, ignore_index=True)\n",
    "osa_hf_common_icd_codes = pd.DataFrame(icd_code_percentage_list_osa_hf, columns=[\"icd_code\", \"percentage\"]).sort_values(by=[\"percentage\"], ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9e569-87bb-41fa-9ddf-275178a8bf9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_common_icd_codes.to_csv(root_path + 'Data/osa_common_icd_codes.csv', index=False)\n",
    "hf_common_icd_codes.to_csv(root_path + 'Data/hf_common_icd_codes.csv', index=False)\n",
    "osa_hf_common_icd_codes.to_csv(root_path + 'Data/osa_hf_common_icd_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e9314-16e8-4536-ba4d-c9f4af28d0eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### most common ICD codes for all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a298292-a3bc-4bba-afe1-17dffcd5298c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For each ICD code, calculate percentage of patients that have the ICD code recorded\n",
    "icd_code_percentage_list = []\n",
    "for icd_code in tqdm(unique_icd_codes):\n",
    "    icd_code_rows = diagnoses_updated[diagnoses_updated['icd_code'] == icd_code]\n",
    "    percentage = icd_code_rows['hadm_id'].unique().size / diagnoses_updated['hadm_id'].unique().size * 100\n",
    "    icd_code_percentage_list.append([icd_code, percentage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc34e67-5f1a-4a75-958e-b98f67a4a089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert list to DataFrame\n",
    "icd_code_percentage_df = pd.DataFrame(icd_code_percentage_list, columns=[\"icd_code\", \"percentage\"])\n",
    "icd_code_percentage_df_label = icd_code_percentage_df.merge(d_icd_diagnoses, on='icd_code')[['icd_code', 'long_title', 'percentage']]\\\n",
    "    .sort_values(by=[\"percentage\"], ascending=False, ignore_index=True)\n",
    "print(\"Lowest percentages: \")\n",
    "icd_code_percentage_df_label.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd7fb1-422e-4b1f-9146-a47b80173703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# icd_code_percentage_df_label.to_csv(root_path + 'Data/common_icd_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff71549-aadd-4fbf-abb8-b34572a07f12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b8ed6-5456-45e4-a618-388e18b0b8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_df_label = pd.read_csv(root_path + 'Data/common_icd_codes.csv')\n",
    "osa_common_icd_codes = pd.read_csv(root_path + 'Data/osa_common_icd_codes.csv')\n",
    "hf_common_icd_codes = pd.read_csv(root_path + 'Data/hf_common_icd_codes.csv')\n",
    "osa_hf_common_icd_codes = pd.read_csv(root_path + 'Data/osa_hf_common_icd_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4b1eb-953b-4dd2-a5e7-fa04514c58c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 0.5 # customized percentage\n",
    "value = icd_code_percentage_df_label[icd_code_percentage_df_label[\"percentage\"] > n].shape[0]\n",
    "osa_icd_code_count = osa_common_icd_codes[osa_common_icd_codes[\"percentage\"] > n].shape[0]\n",
    "hf_icd_code_count = hf_common_icd_codes[hf_common_icd_codes[\"percentage\"] > n].shape[0]\n",
    "osa_hf_icd_code_count = osa_hf_common_icd_codes[osa_hf_common_icd_codes[\"percentage\"] > n].shape[0]\n",
    "\n",
    "print(\"Total count of ICD codes: \", icd_code_percentage_df_label.shape[0])\n",
    "print(f\"Count of ICD codes in > {n} % of all admissions: {value}\\n\")\n",
    "# print(f\"Count of ICD codes in > {n} % of OSA admissions: {osa_icd_code_count}\")\n",
    "# print(f\"Count of ICD codes in > {n} % of HF admissions: {hf_icd_code_count}\")\n",
    "# print(f\"Count of ICD codes in > {n} % of OSA & HF admissions: {osa_hf_icd_code_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbf455-ba07-494e-8b85-a6ff7a7cd537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_df_label['icd_code'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec0358-bf76-4a7c-af7f-70e2db15038f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diagnoses_updated['hadm_id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb90bce-d480-4123-8470-224e5e372f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If doing cutoff percentage value\n",
    "icd_code_keep = icd_code_percentage_df_label[icd_code_percentage_df_label[\"percentage\"] > n]\n",
    "mask = diagnoses_updated['icd_code'].isin(list(icd_code_keep['icd_code']))\n",
    "osa_hf_diagnoses_filtered = diagnoses_updated[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2f8d1-6e49-4af1-a3e9-548469501bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### remove ICD codes that are duplicated\n",
    "Note: Some ICD codes are duplicated because they are the same in version 9 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc7616-fff0-4802-bb87-d1add188c76b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### trace why there are duplicate values after cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c71d3d-8c3b-43aa-ab71-7261d1c7d2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_df_label[icd_code_percentage_df_label[\"percentage\"] > n]['icd_code'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985f8ac-4483-443e-a8d6-ca2c60573ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_percentage_df_label[icd_code_percentage_df_label[\"percentage\"] > n]['icd_code'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbced483-6c5d-4d83-ab13-06617883ab56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_dup = icd_code_percentage_df_label[icd_code_percentage_df_label[\"percentage\"] > n]\\\n",
    "    .drop_duplicates(subset=['icd_code'])\n",
    "print(no_dup.shape[0])\n",
    "print(icd_code_keep.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c488a9b-f64b-4bab-bc75-eb36a33e1d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_codes = icd_code_keep[icd_code_keep['icd_code'].isin(list(no_dup['icd_code']))]\n",
    "mask = icd_code_keep.duplicated(subset=['icd_code'])\n",
    "dup_codes = icd_code_keep[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988da6dd-9f73-4d95-859d-22f8cc481a98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762130d-4ede-413d-adcc-ecd3a7015554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_keep[icd_code_keep['icd_code'] == 'V462']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f745d4d-bb40-49bd-8181-90c16e3e1354",
   "metadata": {},
   "source": [
    "#### remove duplicate codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00508e23-e02d-4a6c-a640-baf25abe43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out duplicate codes\n",
    "mask = osa_hf_diagnoses_filtered['icd_code'].isin(list(dup_codes['icd_code']))\n",
    "osa_hf_diagnoses_filtered = osa_hf_diagnoses_filtered[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34cc91-135a-4196-8f42-343b086c8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_filtered['icd_code'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51cea45-58d8-49d2-8125-bc99f19ef0b9",
   "metadata": {},
   "source": [
    "## Explore hypoxia diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f2e2a-63e1-4486-9bdb-aa69d9165065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hypoxia_icd_code_list = ['R0902', 'J9600', 'J9601', 'J9610', 'J9611', 'J9620', 'J9621', '79902', '51881', '51883', '51884', '79901', 'J9612', 'J9622', 'Z9981']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ce03-5fa6-4ae0-bf6c-4a3a7e3852d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hypoxia_patient_percentage = icd_code_percentage_df_label[icd_code_percentage_df_label['icd_code'].isin(hypoxia_icd_code_list)]\\\n",
    "    .sort_values('percentage', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffb561-00a5-45f8-afc8-41cb7308a98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hypoxia_patient_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b4864-9250-43d7-a961-f632950ffa63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = diagnoses_updated['icd_code'].isin(hypoxia_icd_code_list)\n",
    "osa_hf_diagnoses_hypoxia = diagnoses_updated[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275ed12-ba74-4bbb-b5b0-9fd110459e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"# of unique admissions before filtering: \", diagnoses_updated['hadm_id'].unique().size)\n",
    "print(\"# of unique admissions after filtering: \", osa_hf_diagnoses_filtered['hadm_id'].unique().size, \"\\n\")\n",
    "print(\"# of unique admissions with hypoxia ICD diagnosis code: \", osa_hf_diagnoses_hypoxia['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e62bd-2e5d-4f2d-96e5-edddf9922e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_filtered['icd_code'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a9829-b52d-4063-b56e-1e2d0c2c0b50",
   "metadata": {
    "tags": []
   },
   "source": [
    "<b>Add hypoxia ICD codes regardless of percentage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ba4d7-79cf-4ca3-88bc-71c16c05898c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final = osa_hf_diagnoses_filtered.merge(osa_hf_diagnoses_hypoxia, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0464f70c-046f-4382-ad05-d4c4f225b991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final['icd_code'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2dbc2-512a-46aa-a908-c9432a16703a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1288456-7beb-49d4-b674-42ffdd2fe07f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804f460-52ca-452e-86ff-371e90b34717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f504627-6992-478c-8ed3-908c344698c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"# of unique hadm_id in original cohort: \", osa_hf_diagnoses['hadm_id'].unique().size)\n",
    "print(\"# of unique hadm_id after adding diagnoses: \", osa_hf_diagnoses_final['hadm_id'].unique().size)\n",
    "print(\"# of unique ICD diagnosis codes: \", osa_hf_diagnoses_final['icd_code'].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6856fce-6af6-489b-ac34-80f278a14549",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing\n",
    "for each ICD code (patient-level), get # of diagnosis count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060936c1-09ac-4525-8786-1da363605bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd_code_count = osa_hf_diagnoses_final.groupby(['subject_id', 'hadm_id', 'icd_code', 'long_title'])['seq_num'].count()\n",
    "icd_code_count_df = icd_code_count.reset_index(name='icd_code_count')\n",
    "print(icd_code_count_df.shape[0])\n",
    "icd_code_count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d30110-423d-49a6-9054-17a8631cad10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save long_title for ICD codes\n",
    "labels_icd_code_filtered = icd_code_count_df.drop_duplicates(subset='icd_code')\n",
    "labels_icd_code_filtered = pd.Series(labels_icd_code_filtered['long_title'].values,index=labels_icd_code_filtered['icd_code'].apply(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde5497-1297-4e1e-8c85-7eda132f8d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_icd_code_filtered.to_csv(root_path + 'Data/labels_icd_code_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd1a43-d025-4f04-bb4f-2405e3ad627d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final_pivot = icd_code_count_df.pivot(index=['subject_id', 'hadm_id'], columns='icd_code', values='icd_code_count')\n",
    "print(osa_hf_diagnoses_final_pivot.shape)\n",
    "osa_hf_diagnoses_final_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486b3db-4928-4b48-a31a-fc306f9fad73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final_pivot_df = osa_hf_diagnoses_final_pivot\\\n",
    "    .rename_axis(columns=None)\\\n",
    "    .reset_index()\\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11976485-653f-45dc-8144-6ea24f679890",
   "metadata": {},
   "source": [
    "<b>Look if there are nonbinary values (there should only be 1 count for each diagnosis)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f8a43-7c7f-4a6e-b2d9-94dae62ff093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_diagnoses_final_pivot_df[osa_hf_diagnoses_final_pivot_df.isin([2]).any(axis=1)].shape[0])\n",
    "osa_hf_diagnoses_final_pivot_df.columns[osa_hf_diagnoses_final_pivot_df.isin([2]).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2dc768-4e32-40a7-bf1a-ab36991b11e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace nonbinary values\n",
    "osa_hf_diagnoses_final_pivot_df.where(osa_hf_diagnoses_final_pivot_df != 2, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c22372-7169-4b90-99e7-560d2446d2f5",
   "metadata": {},
   "source": [
    "## Merge with cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51a639-e36c-4906-b912-40578981041b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_diagnoses_final_pivot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc117c2-2758-4823-aa29-c6fb39a93fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_diagnoses_final_pivot_df['hadm_id'].unique().size)\n",
    "print(osa_hf_diagnoses_filtered['hadm_id'].unique().size)\n",
    "print(osa_hf_diagnoses_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9f8f4-bedf-4b0f-9b8e-b6bec4c0f1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_icd_code_count = osa_hf_diagnoses_filtered.loc[:, 'subject_id':'charlson']\\\n",
    "    .drop_duplicates(subset=['subject_id', 'hadm_id'])\\\n",
    "    .merge(osa_hf_diagnoses_final_pivot_df, on=['subject_id', 'hadm_id'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b224592-77ef-4d58-a5f9-3dd04a09ceba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_icd_code_count.shape)\n",
    "# osa_hf_labevents_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b30e13-ff27-4cf5-9469-5942cd07b517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to CSV\n",
    "# osa_hf_icd_code_count.to_csv(root_path + 'Cohort/osa_hf_diagnosis_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90306e8a-b29d-4d33-b223-f5f534476ce8",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f86f62-b04d-4255-b5ca-5a8470bdd0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(root_path + \"2025/cohort/osa_hf_all_features_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4487cd-6f64-44ae-9342-d22509b137a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_id_only = data.loc[:, ['subject_id', 'hadm_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899ca9c-4f26-4f4c-a6d8-5e7d0f46418b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emar = pd.read_csv(mimic4_path + 'hosp/emar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa619f-e020-4e2f-920a-0d344fe52272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emar_detail = pd.read_csv(mimic4_path + 'hosp/emar_detail.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e931bfc-389c-4ea0-97a5-e17cac089b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pharmacy = pd.read_csv(mimic4_path + 'hosp/pharmacy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603543a-b210-4118-b0ef-a02beeb7c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures_icd = pd.read_csv(mimic4_path + 'hosp/procedures_icd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627dbc-50ef-444b-a2c2-be84c62e6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_icd_procedures = pd.read_csv(mimic4_path + 'hosp/d_icd_procedures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409475d-de57-49bf-8eb7-759a593db5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b103eb3-19d4-484c-ad52-c65d7e964ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55450bb-4885-4bbd-90f7-d6aa776346fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# V. ADD MEDICATIONS\n",
    "\n",
    "Use binary value to represent medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e08727-8a30-4b83-bef3-6077f29fc29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge medications (emar, emar_detail, and pharmacy)\n",
    "osa_hf_med = data_id_only.merge(emar, how = 'left', on = ['subject_id', 'hadm_id'])\n",
    "osa_hf_med = osa_hf_med.merge(emar_detail[['subject_id', 'emar_id', 'emar_seq', 'dose_given', 'dose_given_unit', 'pharmacy_id']], how = 'left', on = ['subject_id','emar_id', 'emar_seq', 'pharmacy_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed74f7-25fe-4fb7-961a-5c27b736eef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_med = osa_hf_med.merge(pharmacy[['subject_id', 'hadm_id', 'pharmacy_id', 'medication', 'starttime', 'stoptime']], how = 'left', on = ['subject_id','hadm_id', 'pharmacy_id', 'medication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cec57-2741-43b0-927e-ec59722dc5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_med.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b2267-3e9e-40b7-843a-c9484be40c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Unique patients: \", osa_hf_med['subject_id'].unique().size)\n",
    "print(\"Unique admissions: \", osa_hf_med['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41881075-13ae-4316-9025-ca2a61217b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medications = osa_hf_med[['pharmacy_id', 'medication']].drop_duplicates(subset='pharmacy_id')\n",
    "# medications = pd.Series(medications['medication'].values,index=medications['emar_id'].apply(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd922d8-aedf-490a-9a1b-14280fb3976b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6e85b-6b51-42b1-a9c8-084f928bdce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medications['medication'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa5ff3-d374-4ac4-a5cf-ad601ffe8654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medications['pharmacy_id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5f910-5410-4a61-ac57-993ae35fa538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_med['medication'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea37a1-5c3f-47a1-97d1-461c6896afa8",
   "metadata": {},
   "source": [
    "#### only keep certain percentage % of medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3a269-2359-4d50-b93c-2ab192df9d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_med = osa_hf_med['medication'].unique()\n",
    "print(\"# of unique medications: \", unique_med.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff271e52-089c-4801-bd71-6c8250e4cbbd",
   "metadata": {},
   "source": [
    "<b>For each lab, calculate percentage of patients that have the lab recorded</b>\n",
    "\n",
    "Uncomment only if needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ed9be-aefd-4979-93ca-fdddfd3b8c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## -- Takes a while\n",
    "\n",
    "# med_percentage_list = []\n",
    "# for med in tqdm(unique_med):\n",
    "#     med_rows = osa_hf_med[osa_hf_med['medication'] == med]\n",
    "#     percentage = med_rows['hadm_id'].unique().size / osa_hf_med['hadm_id'].unique().size * 100\n",
    "#     med_percentage_list.append([med, percentage])\n",
    "\n",
    "# # Convert list to DataFrame\n",
    "# med_percentage_df = pd.DataFrame(med_percentage_list, columns=[\"medication\", \"percentage\"])\n",
    "# med_percentage_df.sort_values(by=[\"percentage\"], ascending=False, ignore_index=True, inplace=True)\n",
    "# print(\"Lowest percentages: \")\n",
    "# med_percentage_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b634e58-fff2-460f-87dc-ea7c414f12ba",
   "metadata": {},
   "source": [
    "<b>To CSV file (medications for OSA-HF cohort)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ff5a9-f232-4a4b-9731-e99e042f5e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- Uncomment if needed --\n",
    "# med_percentage_df.to_csv(root_path + '2025/data/common_medications.csv')\n",
    "\n",
    "med_percentage_df = pd.read_csv(root_path + '2025/data/common_medications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa6f8b-9675-4cce-b8c9-a332fa5375da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 0.5 # customized percentage\n",
    "value = med_percentage_df[med_percentage_df[\"percentage\"] > n].shape[0]\n",
    "print(f\"Number of medications in > {n} % of admissions: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f1b78-70c4-42f4-8eee-b4f10b19da0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If doing cutoff percentage value\n",
    "\n",
    "med_keep = med_percentage_df[med_percentage_df[\"percentage\"] > n]\n",
    "\n",
    "osa_hf_med_cleaned = osa_hf_med.copy()\n",
    "\n",
    "osa_hf_med_cleaned['medication'] = osa_hf_med['medication'].where(\n",
    "    osa_hf_med['medication'].isin(med_keep['medication']), \n",
    "    other=pd.NA  # or use np.nan if preferred\n",
    ")\n",
    "\n",
    "## -- OLD CODE -- for removing admissions\n",
    "# mask = osa_hf_med['medication'].isin(list(med_keep['medication']))\n",
    "# osa_hf_med_cleaned = osa_hf_med[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c021ce3-1d92-4434-bdae-baeea57f08df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_med_cleaned['medication'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809af8d-9733-4126-81b2-4c99f14c4467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_med_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9e33d-1fed-4681-ae18-44ad79d00cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.shape[0])\n",
    "print(osa_hf_med_cleaned['hadm_id'].unique().size)\n",
    "osa_hf_med_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fcf20-fa0d-4766-9bde-e72c3fea83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- AFTER DROPPING DUPLICATES\n",
    "osa_hf_med_cleaned.drop_duplicates(inplace=True)\n",
    "\n",
    "print(data.shape[0])\n",
    "print(osa_hf_med_cleaned['hadm_id'].unique().size)\n",
    "osa_hf_med_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10916a8-e538-437a-b630-7c9cb67ed040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Many rows have null values in some columns (e.g. dose_given)\n",
    "df_no_null = osa_hf_med_cleaned.dropna()\n",
    "print(df_no_null['hadm_id'].nunique())\n",
    "df_no_null.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269226eb-3700-4f63-8ed3-8cb9c36a21ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "osa_hf_med_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d2412-27f7-408f-ae25-9cc145abfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_med_cleaned_count = osa_hf_med_cleaned.groupby(['subject_id', 'hadm_id','medication'])['charttime'].count()\n",
    "\n",
    "## -- Uncomment if using binary value (true or false if admission has particular medication) --\n",
    "osa_hf_med_cleaned_count.where(osa_hf_med_cleaned_count <= 1, 1, inplace=True)\n",
    "\n",
    "osa_hf_med_cleaned_count_df = osa_hf_med_cleaned_count.reset_index(name='count')\n",
    "\n",
    "print(osa_hf_med_cleaned_count_df.shape[0])\n",
    "osa_hf_med_cleaned_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad77922-dc3f-47da-8a09-5cc71489b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_med_cleaned_count_df.sort_values(by = 'count', ascending = False).head()\n",
    "\n",
    "## -- Graph used if NOT using binary value --\n",
    "osa_hf_med_cleaned_count_df['count'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa17047-fa57-4429-bf18-7e418183a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot DataFrame -> icd_code as columns\n",
    "df_pivot = osa_hf_med_cleaned_count_df\\\n",
    "    .pivot(index=['subject_id', 'hadm_id'], columns=['medication'], values='count')\n",
    "\n",
    "osa_hf_med_cleaned_pivot = df_pivot\\\n",
    "    .rename_axis(columns=None)\\\n",
    "    .reset_index()\n",
    "\n",
    "osa_hf_med_cleaned_pivot = osa_hf_med_cleaned_pivot\\\n",
    "    .merge(osa_hf_med_cleaned[['subject_id', 'hadm_id']].drop_duplicates(subset=['subject_id', 'hadm_id']), on=['subject_id', 'hadm_id'], how='outer', validate=\"1:1\")\\\n",
    "    .fillna(0)\\\n",
    "    .astype(int)\n",
    "\n",
    "\n",
    "print(osa_hf_med_cleaned_pivot.shape)\n",
    "osa_hf_med_cleaned_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467658c3-f0aa-4091-8639-d97e85035f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medication dataframe\n",
    "osa_hf_med_final = osa_hf_med_cleaned.loc[:, ['subject_id', 'hadm_id']]\\\n",
    "    .drop_duplicates(subset=['subject_id', 'hadm_id'])\\\n",
    "    .merge(osa_hf_med_cleaned_pivot, on=['subject_id', 'hadm_id'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c7da0-92e0-4acc-9f0e-bee7a473fae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "osa_hf_med_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b259d0-93c4-48c3-ab66-d7e824621161",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Using count --\n",
    "# osa_hf_med_final.to_csv(root_path + \"2025/cohort/osa_hf_med.csv\")\n",
    "\n",
    "## -- Using binary --\n",
    "# osa_hf_med_final.to_csv(root_path + \"2025/cohort/osa_hf_med_binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e554e-282d-440b-a13c-790889c882f6",
   "metadata": {},
   "source": [
    "#### Explore medications (using count) within cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303c8d8-c3f9-47ea-ae12-5abad6cf27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_med = pd.read_csv(root_path + \"2025/cohort/osa_hf_med.csv\").drop(columns=['Unnamed: 0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c9597-f710-4f2c-9ae3-817d2cbd6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_med.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f1e66-ae21-40e7-92ad-bf99ad8b1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of medication where multiple patients have a count > 41\n",
    "osa_hf_med['ALPRAZolam'].value_counts().sort_index(ascending=False).iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d827a7-85b9-4140-824e-0a067f8ba42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of medication where multiple patients have a count > 133\n",
    "osa_hf_med['sevelamer CARBONATE'].value_counts().sort_index(ascending=False).iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf4970-74a1-4673-82f9-ccb8ec72df97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VI. ADD PROCEDURES\n",
    "\n",
    "Use count of procedures per admission to represent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653cce8-62e5-4214-b9b5-e9394ccb4e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "procedures_icd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1323a-5c7f-41af-aa0a-6f9af2cfdb07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_icd_procedures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b0d53-3cb9-4c0f-b935-0aeb27723eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge medications (emar, emar_detail, and pharmacy)\n",
    "osa_hf_procedures = data_id_only.merge(procedures_icd, how = 'left', on = ['subject_id', 'hadm_id'])\n",
    "osa_hf_procedures = osa_hf_procedures.merge(d_icd_procedures, how = 'left', on = ['icd_code','icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c511a07-4af0-4e0c-bd53-b9d4d60cf83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(osa_hf_procedures.shape)\n",
    "osa_hf_procedures.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aee82-e039-42ab-9664-dbe3ea03ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by subject_id and check if all icd_code entries are null\n",
    "mask = osa_hf_procedures.groupby('subject_id')['icd_code'].apply(lambda x: x.isnull().all())\n",
    "\n",
    "# Filter to only include those subject_ids\n",
    "result = osa_hf_procedures[osa_hf_procedures['subject_id'].isin(mask[mask].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdebb758-0a68-4333-9dc3-36c3256f0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of patients who had no procedures done across all admissions: \", len(result['subject_id'].unique()))\n",
    "print(\"# of admissions who had no procedures done across all admissions: \", len(result['hadm_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed47734-79f7-4473-94ad-d88d02c981c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Unique patients: \", osa_hf_procedures['subject_id'].unique().size)\n",
    "print(\"Unique admissions: \", osa_hf_procedures['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56ca55-3cc8-4bdf-a9db-99cbe6b3b257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_procedures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d7760-0635-4b0a-9d7b-c27d9a2d0d2c",
   "metadata": {},
   "source": [
    "<b>Store icd_code and long_title for easy conversion</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cb143-f4de-44a8-9198-15df398ed717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_procedures = osa_hf_procedures[['icd_code', 'long_title']].drop_duplicates(subset='icd_code')\n",
    "labels_procedures = pd.Series(labels_procedures['long_title'].values,index=labels_procedures['icd_code'].apply(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53903b-cbe8-4641-9af9-7da2be261908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_procedures.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628c00a-6239-4249-a882-b4c4f82b9088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_procedures.to_csv(root_path + '2025/data/labels_procedures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c87b5-2010-4aa9-aa11-18472afe6d60",
   "metadata": {},
   "source": [
    "#### only keep certain percentage % of procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00640db4-3698-41ca-a967-55ee94e7e572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_procedures = osa_hf_procedures['icd_code'].unique()\n",
    "print(\"# of unique procedures: \", unique_procedures.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75f7dc-1ca1-45aa-8cf6-fa2c13f6931e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For each lab, calculate percentage of patients that have the lab recorded\n",
    "procedure_percentage_list = []\n",
    "for icd_code in tqdm(unique_procedures):\n",
    "    procedure_rows = osa_hf_procedures[osa_hf_procedures['icd_code'] == icd_code]\n",
    "    percentage = procedure_rows['hadm_id'].unique().size / osa_hf_procedures['hadm_id'].unique().size * 100\n",
    "    procedure_percentage_list.append([icd_code, percentage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba103e-7db0-4cb1-91c3-8c1243b426ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert list to DataFrame\n",
    "procedure_percentage_df = pd.DataFrame(procedure_percentage_list, columns=[\"icd_code\", \"percentage\"])\n",
    "procedure_percentage_df.sort_values(by=[\"percentage\"], ascending=False, ignore_index=True, inplace=True)\n",
    "print(\"Lowest percentages: \")\n",
    "procedure_percentage_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad6471-2a52-4a5a-ab49-5c3fac02d902",
   "metadata": {},
   "source": [
    "<b>To CSV file (procedures for OSA-HF cohort)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850048f-2f5e-4c16-b108-520bf9e06d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# procedure_percentage_df.to_csv(root_path + '2025/data/common_procedures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4e8fc-e371-428d-ab6c-0e189cf7dde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "procedure_percentage_df = pd.read_csv(root_path + '2025/data/common_procedures.csv', index_col=False)\n",
    "\n",
    "n = 0.5 # customized percentage\n",
    "value = procedure_percentage_df[procedure_percentage_df[\"percentage\"] > n].shape[0]\n",
    "print(f\"Number of procedures in > {n} % of admissions: {value}\")\n",
    "\n",
    "#note: even .1% drops the number from 5k+ to 405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ebb53-3ae3-4c05-b0af-c4135cd20598",
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_percentage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394b97b-651f-4da1-9ed0-e1080c14acb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If doing cutoff percentage value\n",
    "\n",
    "procedure_keep = procedure_percentage_df[procedure_percentage_df[\"percentage\"] > n]\n",
    "\n",
    "osa_hf_procedures_cleaned = osa_hf_procedures.copy()\n",
    "\n",
    "osa_hf_procedures_cleaned['icd_code'] = osa_hf_procedures['icd_code'].where(\n",
    "    osa_hf_procedures['icd_code'].isin(procedure_keep['icd_code']), \n",
    "    other=pd.NA  # or use np.nan if preferred\n",
    ")\n",
    "\n",
    "osa_hf_procedures_cleaned['long_title'] = osa_hf_procedures['long_title'].where(\n",
    "    osa_hf_procedures['icd_code'].isin(procedure_keep['icd_code']), \n",
    "    other=pd.NA  # or use np.nan if preferred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bb14d-278e-4f6f-8e7e-054b84e3f531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2eec4-6809-4cc7-927e-f9d813be6f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Original # of admissions:\", data.shape[0])\n",
    "print(\"Original # of patients:\", data['subject_id'].unique().size, \"\\n\")\n",
    "print(\"# of admissions after adding procedures:\", osa_hf_procedures_cleaned['hadm_id'].unique().size)\n",
    "print(\"# of patients after adding procedures:\", osa_hf_procedures_cleaned['subject_id'].unique().size)\n",
    "osa_hf_procedures_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09a2e-668e-4ae9-8758-035377a41647",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned['long_title'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bcb6d-2421-46a1-8c6e-5d552082c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned['icd_code'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa18b4-1dc9-41aa-93b8-66e8a766c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3781e-1715-4d3c-9b27-d05ac1a3995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned_count = osa_hf_procedures_cleaned.groupby(['subject_id', 'hadm_id','icd_code'])['seq_num'].count()\n",
    "osa_hf_procedures_cleaned_count_df = osa_hf_procedures_cleaned_count.reset_index(name='count')\n",
    "\n",
    "print(osa_hf_procedures_cleaned_count_df.shape[0])\n",
    "osa_hf_procedures_cleaned_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1b907-7931-4185-b1db-22309e2081e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned_count_df.sort_values(by = 'count', ascending = False).head()\n",
    "osa_hf_procedures_cleaned_count_df['count'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170bd13-5eec-46ed-9bd9-b202314db85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot DataFrame -> icd_code as columns\n",
    "df_pivot = osa_hf_procedures_cleaned_count_df\\\n",
    "    .pivot(index=['subject_id', 'hadm_id'], columns=['icd_code'], values='count')\n",
    "\n",
    "# Keep all rows, regardless if they have an abnormal value recorded\n",
    "osa_hf_procedures_cleaned_pivot = df_pivot\\\n",
    "    .rename_axis(columns=None)\\\n",
    "    .reset_index()\n",
    "\n",
    "osa_hf_procedures_cleaned_pivot = osa_hf_procedures_cleaned_pivot\\\n",
    "    .merge(osa_hf_procedures_cleaned[['subject_id', 'hadm_id']].drop_duplicates(subset=['subject_id', 'hadm_id']), on=['subject_id', 'hadm_id'], how='outer', validate=\"1:1\")\\\n",
    "    .fillna(0)\\\n",
    "    .astype(int)\n",
    "\n",
    "\n",
    "print(osa_hf_procedures_cleaned_pivot.shape)\n",
    "osa_hf_procedures_cleaned_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306736a-6ec4-410d-af38-860720710fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc065ef-a796-4010-b219-febb77cea1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure dataframe\n",
    "osa_hf_procedures_final = osa_hf_procedures_cleaned.loc[:, ['subject_id', 'hadm_id']]\\\n",
    "    .drop_duplicates(subset=['subject_id', 'hadm_id'])\\\n",
    "    .merge(osa_hf_procedures_cleaned_pivot, on=['subject_id', 'hadm_id'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e634514-b4db-4ce9-9a80-6317d5e1de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afcc19e-34e5-4d07-b881-c49b3fab0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_procedures_final.to_csv(root_path + \"2025/cohort/osa_hf_procedures.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06580c2-bfa0-4adb-b7bc-884439a3e095",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VII. COHORT FINAL MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75788743-aeb0-45a9-b7d5-aa2e585e753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Using count --\n",
    "# osa_hf_med = pd.read_csv(root_path + \"2025/cohort/osa_hf_med.csv\", index_col=0)\n",
    "\n",
    "## -- Using binary --\n",
    "osa_hf_med = pd.read_csv(root_path + \"2025/cohort/osa_hf_med_binary.csv\", index_col=0)\n",
    "\n",
    "osa_hf_procedure = pd.read_csv(root_path + \"2025/cohort/osa_hf_procedures.csv\", index_col=0)\n",
    "osa_hf_demo_lab_diagnosis = pd.read_csv(root_path + \"2025/cohort/osa_hf_all_features_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33689c8-3435-4fa0-a0ea-1a4a6114f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_med['Acetaminophen_med_count'] = osa_hf_med['Acetaminophen']\n",
    "osa_hf_med['Digoxin_med_count'] = osa_hf_med['Digoxin']\n",
    "osa_hf_med['Vancomycin_med_count'] = osa_hf_med['Vancomycin']\n",
    "osa_hf_med.drop(columns=['Acetaminophen', 'Digoxin', 'Vancomycin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82f0d0-1c60-48f5-8a7a-51cd16b54724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_medications_procedures = data_id_only.merge(osa_hf_med, how = 'left', on = ['subject_id', 'hadm_id'])\n",
    "data_medications_procedures = data_medications_procedures.merge(osa_hf_procedure, how = 'left', on = ['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5a3c6-4953-4afa-8f1b-0c3394ea72f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_medications_procedures.drop(columns=['emar_id', 'poe_id', 'event_txt', 'enter_provider_id'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cc7c6-369e-4743-a0d3-f8800f91b40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"# Unique patients: \", data_medications_procedures['subject_id'].unique().size)\n",
    "print(\"# Unique admissions: \", data_medications_procedures['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2258e-d622-4f20-8f19-5ea8ca3e7fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_medications_procedures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcab0d-ce0d-45c9-afd6-0e58f1e3e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications_procedures.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be670b-4f04-4597-9424-c4b789980968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_medications_procedures.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbe716-be2a-4db5-ab0f-45660b4dc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "osa_hf_demo_lab_diagnosis_med_procedure = osa_hf_demo_lab_diagnosis.merge(data_medications_procedures, how = 'left', on = ['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492cddc-ecc6-46d5-b26b-cf58da521fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Unique patients: \", osa_hf_demo_lab_diagnosis_med_procedure['subject_id'].unique().size)\n",
    "print(\"# Unique admissions: \", osa_hf_demo_lab_diagnosis_med_procedure['hadm_id'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602c7fa-46e6-4968-9b7d-b027ff5fc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Checks for abnormal columns.\n",
    "for column in osa_hf_demo_lab_diagnosis_med_procedure:\n",
    "    if column.endswith(\"_y\") | column.endswith(\"_x\"):\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba76b64-bc99-4a52-a73b-dd21a95d6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Using medication count --\n",
    "# osa_hf_demo_lab_diagnosis_med_procedure.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_med_procedure.csv\")\n",
    "\n",
    "## -- Using binary value for medications --\n",
    "# osa_hf_demo_lab_diagnosis_med_procedure.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaadd22-0fe3-4c07-80d7-27be49b28ebb",
   "metadata": {},
   "source": [
    "#### Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e5dcc-04d5-459e-bb2d-216cebfb8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = osa_hf_demo_lab_diagnosis_med_procedure.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452a90b-6565-4bb4-bc42-2cb24ab1eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567cb446-69e7-44d0-ab91-c1a598dfaf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = X['group']\n",
    "print(labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ad13f-b13d-4051-91e5-f5c108c6604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labs = X.iloc[:, 16:233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d0c66-f307-46ea-99e6-cbb53bb019df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = X.drop(columns=['osa', 'hf', 'group_name', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ae43d-1f0a-43ce-a138-eafa3842ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize = ['age', 'los', 'charlson', 'bmi']\n",
    "cols_to_normalize.extend(list(X_labs.columns))\n",
    "cols_to_ohe = ['gender', 'race_classified', 'insurance', 'admission_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6a361-e02e-4e16-bd2e-cd02eb80069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned[cols_to_normalize].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff64fe-a589-443a-bf11-210f077c2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_cleaned[cols_to_normalize].isna().sum().sum())  # Check NaNs\n",
    "print((X_cleaned[cols_to_normalize] < -1).sum().sum())  # Check negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c058b6-8e23-4353-a1a2-6d4dd146124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned[cols_to_normalize] = np.log1p(X_cleaned[cols_to_normalize]) \n",
    "scaler = MinMaxScaler() \n",
    "X_cleaned[cols_to_normalize] = scaler.fit_transform(X_cleaned[cols_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bbe1e-b8d4-49e6-b4e6-018bb155bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed_with_id = one_hot_encode(X_cleaned, cols_to_ohe, drop_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3ecb6-3e35-453f-b576-3ed0dfe98eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_processed_with_id.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796f0b8-2d3f-4358-bebd-8de31421385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed_without_id = one_hot_encode(X_cleaned, cols_to_ohe, drop_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616adbd-655d-4e48-81c1-3c825a0a1e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_processed_without_id.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0899ff-8357-4fe2-81ef-00c6d81b7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Using medication count --\n",
    "# X_processed_with_id.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_med_procedure_processed_with_id.csv\", index=False)\n",
    "\n",
    "## -- Using binary value for medication\n",
    "# X_processed_with_id.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_processed_with_id.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac13e5-66ab-4805-b4e2-ff48c6683990",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Using medication count --\n",
    "# X_processed_without_id.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_med_procedure_processed_without_id.csv\", index=False)\n",
    "\n",
    "## -- Using binary value for medication\n",
    "# X_processed_without_id.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_processed_without_id.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96369c4-a4f5-417b-bfe6-cad825ff6288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eac55cb-0daf-4aa1-8564-3b1b7398b1f4",
   "metadata": {},
   "source": [
    "# VIII. REMOVE FEATURES WITH LOW VARIANCE\n",
    "**Removed features with < 1% variance.**\n",
    "\n",
    "1155 features --> 576 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8495a7-d1a1-4b50-8071-13bfcd3d3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/global/cfs/projectdirs/m1532/Projects_MVP/Sophia/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde886da-526a-475c-a4cb-6c6ab63698fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_cohort_with_id(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_processed_with_id.csv\")\n",
    "X_scaled, y = read_cohort_without_id(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_processed_with_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0daf7a-7cab-4ac5-bda4-ee7efba4c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw, y_raw = read_cohort_with_id(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc6c8d-060c-4056-9338-8d3f40858920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725fa4f-8c27-4eef-bc2a-6e7e3791a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8266666-c07c-4b34-9473-1a3a21183eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsity:\n",
    "sparsity = sum((X_scaled == 0).astype(int).sum())/X_scaled.size\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2017a06-e3a8-4d22-acff-f157004d583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance of each column\n",
    "variances = X_scaled.var()\n",
    "print(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed6cc7-9050-4f78-b3cd-7e7bbbb2ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for feature, variance in variances.items():\n",
    "    if (variance >= 0.01):\n",
    "        count = count+1\n",
    "print(\"Number of features after removing those with a variance of less than 1%: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ad089-680a-4995-af29-95a0c102e1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## -- With ID --\n",
    "kept_cols = ['subject_id', 'hadm_id', 'group', 'group_name']\n",
    "\n",
    "# Set a threshold (e.g., 10)\n",
    "threshold = .01\n",
    "\n",
    "# Initialize and fit the VarianceThreshold selector\n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "selector.fit(X.drop(columns=kept_cols))\n",
    "\n",
    "# Get the variances of the features\n",
    "feature_variances = selector.variances_\n",
    "print(\"Feature Variances:\", feature_variances)\n",
    "\n",
    "# Get the indices of the selected (non-removed) features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "# print(\"Selected Feature Indices:\", selected_feature_indices)\n",
    "\n",
    "# Transform the DataFrame to keep only the selected features\n",
    "X_scaled_transformed_with_id = X_scaled.iloc[:, selected_feature_indices]\n",
    "X_scaled_transformed_with_id = pd.concat([X[kept_cols], X_scaled_transformed_with_id], axis=1)\n",
    "print(\"Transformed DataFrame:\")\n",
    "X_scaled_transformed_with_id.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203e78d-1614-412b-ad9d-6d315687124d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## -- Without ID -- \n",
    "\n",
    "# Set a threshold (e.g., 10)\n",
    "threshold = .01\n",
    "\n",
    "# Initialize and fit the VarianceThreshold selector\n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "selector.fit(X_scaled)\n",
    "\n",
    "# Get the variances of the features\n",
    "feature_variances = selector.variances_\n",
    "print(\"Feature Variances:\", feature_variances)\n",
    "\n",
    "# Get the indices of the selected (non-removed) features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "# print(\"Selected Feature Indices:\", selected_feature_indices)\n",
    "\n",
    "# Transform the DataFrame to keep only the selected features\n",
    "X_scaled_transformed = X_scaled.iloc[:, selected_feature_indices]\n",
    "print(\"Transformed DataFrame:\")\n",
    "X_scaled_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7abaf-d1c1-46b1-9de0-a8d6a959848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge based on index\n",
    "X_scaled_transformed = pd.merge(y, X_scaled_transformed, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a299b2-a502-4902-bc66-ba2acb48bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_transformed_with_id.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_reduced_with_id.csv\")\n",
    "X_scaled_transformed.to_csv(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_reduced_without_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f64fb-234c-4ce2-9efb-4ebaaf143f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_transformed.to_csv(\"cleaned_inputs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876cee7-df12-4840-997f-f46a2bfb9bbe",
   "metadata": {},
   "source": [
    "### Among those that are kept, which are labs, diagnoses, etc. ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c0fd2-9c4a-431b-9c11-a7a14c3e56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629a334-04dd-4382-a0e7-b615ca60e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "medications = pd.read_csv(root_path + \"2025/data/common_medications.csv\", index_col=0)['medication'].tolist()\n",
    "procedures = pd.read_csv(root_path + \"2025/data/common_procedures.csv\", index_col=0)['icd_code'].tolist()\n",
    "diagnoses = pd.read_csv(root_path + \"2025/data/labels_icd_code_filtered.csv\", index_col=0)['long_title'].tolist()\n",
    "labs = pd.read_csv(root_path + \"2025/data/labels_labevents_filtered.csv\", index_col=0)['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56fff0-6d38-43bf-8349-4cf82afd1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Using reduced feature space (n=666)\n",
    "kept_medications = []\n",
    "kept_procedures = []\n",
    "kept_diagnoses = []\n",
    "kept_labs = []\n",
    "kept_demographics = []\n",
    "\n",
    "for column in X_scaled_transformed:\n",
    "    # Handle columns with suffix\n",
    "    suffix = [\".1\", \".2\", \".3\", \".4\", \".5\"]\n",
    "\n",
    "    for idx, string in enumerate(suffix):\n",
    "        if column.endswith(suffix[idx]):\n",
    "            column = column[:-len(suffix[idx])]\n",
    "    \n",
    "    if (column in medications) | (\"_med_count\" in column):\n",
    "        kept_medications.append(column)\n",
    "    elif column in procedures:\n",
    "        kept_procedures.append(column)\n",
    "    elif column in diagnoses:\n",
    "        kept_diagnoses.append(column)\n",
    "    elif column in labs:\n",
    "        kept_labs.append(column)\n",
    "    else:\n",
    "        kept_demographics.append(column)\n",
    "\n",
    "print(\"Number of medication features (reduced): \", len(kept_medications))\n",
    "print(\"Number of procedure features (reduced): \", len(kept_procedures))\n",
    "print(\"Number of diagnosis features (reduced): \", len(kept_diagnoses))\n",
    "print(\"Number of lab features (reduced): \", len(kept_labs))\n",
    "print(\"Number of demographic features (reduced): \", len(kept_demographics))\n",
    "print(\"Total number of features (reduced): \", len(kept_medications) + len(kept_procedures) + len(kept_diagnoses) + len(kept_labs) + len(kept_demographics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b350756-447a-4902-ad01-15330baf4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d4d18-6131-437f-bed9-a1d061c4c5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95a4d3-eaaf-4fc2-a42a-7ddbd8f3763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Using all feature space (n=1156)\n",
    "all_medications = []\n",
    "all_procedures = []\n",
    "all_diagnoses = []\n",
    "all_labs = []\n",
    "all_demographics = []\n",
    "\n",
    "for column in X_scaled:\n",
    "    # Handle columns with suffix\n",
    "    suffix = [\".1\", \".2\", \".3\", \".4\", \".5\"]\n",
    "\n",
    "    for idx, string in enumerate(suffix):\n",
    "        if column.endswith(suffix[idx]):\n",
    "            column = column[:-len(suffix[idx])]\n",
    "    \n",
    "    if (column in medications) | (\"_med_count\" in column):\n",
    "        all_medications.append(column)\n",
    "    elif column in procedures:\n",
    "        all_procedures.append(column)\n",
    "    elif column in diagnoses:\n",
    "        all_diagnoses.append(column)\n",
    "    elif column in labs:\n",
    "        all_labs.append(column)\n",
    "    else:\n",
    "        all_demographics.append(column)\n",
    "\n",
    "print(\"Number of medication features (all): \", len(all_medications))\n",
    "print(\"Number of procedure features (all): \", len(all_procedures))\n",
    "print(\"Number of diagnosis features (all): \", len(all_diagnoses))\n",
    "print(\"Number of lab features (all): \", len(all_labs))\n",
    "print(\"Number of demographic features (all): \", len(all_demographics))\n",
    "print(\"Total number of features (all): \", len(all_medications) + len(all_procedures) + len(all_diagnoses) + len(all_labs) + len(all_demographics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5797c09-2c86-40b6-bba8-bf61df19da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Medication] # of removed features: \", len(all_medications) - len(kept_medications))\n",
    "print(\"[Procedure] # of removed features: \", len(all_procedures) - len(kept_procedures))\n",
    "print(\"[Diagnosis] # of removed features: \", len(all_diagnoses) - len(kept_diagnoses))\n",
    "print(\"[Lab] # of removed features: \", len(all_labs) - len(kept_labs))\n",
    "print(\"[Demographic] # of removed features: \", len(all_demographics) - len(kept_demographics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b6cb4-f16c-481c-8b16-b25aee2e7be6",
   "metadata": {},
   "source": [
    "# VIII. LATENT SPACE EXTRACTION\n",
    "Using Autoencoder (50 dimensions) -> UMAP (2 dimensions)\n",
    "\n",
    "** Prior to this, conduct a grid search with cohort on all hyperparameters for Autoencoder architecture and UMAP (separately)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304734e-1549-4dbe-8303-4133427dd7e5",
   "metadata": {},
   "source": [
    "## AE-UMAP on reduced feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38656ed-a42c-4185-9bce-123153df1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_transformed, y = read_cohort_without_id(root_path + \"2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56157661-e1b2-4628-ab1e-6a65077c7f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled_transformed, y, test_size = 0.3, random_state = 42)\n",
    "# print(y_train.value_counts())\n",
    "# print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fcf469-130f-453b-af40-1bffc2ed814d",
   "metadata": {},
   "source": [
    "#### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c15bfd-483d-43bb-a27e-3dd94fd3daec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set the seed\n",
    "# set_seed(42)\n",
    "\n",
    "# # Check if CUDA (GPU) is available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# #_ for sparse matrix data type only\n",
    "# # X_train_dense = csr_matrix(X_train).toarray() \n",
    "# # X_test_dense = csr_matrix(X_test).toarray()\n",
    "# # X_train_tensor = torch.tensor(X_train_dense, dtype=torch.float32).to(device)\n",
    "# # X_test_tensor = torch.tensor(X_test_dense, dtype=torch.float32).to(device)\n",
    "\n",
    "# X_train_np = X_train.to_numpy()\n",
    "# X_test_np = X_test.to_numpy()\n",
    "# X_scaled_np = X_scaled_transformed.to_numpy()\n",
    "\n",
    "# X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32).to(device)\n",
    "# X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32).to(device)\n",
    "\n",
    "# #- all data points\n",
    "# #X_normalized_dense = X_normalized.toarray()\n",
    "# X_tensor = torch.tensor(X_scaled_np, dtype = torch.float32).to(device)\n",
    "\n",
    "# # Define the model\n",
    "# input_dim = X_train_np.shape[1]  # Example input dimension\n",
    "# encoding_dims = 50  # Example encoding dimension\n",
    "# model = Autoencoder(input_dim, encoding_dims).to(device)\n",
    "\n",
    "# # Define the optimizer and loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)  # Using Adam optimizer\n",
    "# criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "\n",
    "# # Convert data into PyTorch DataLoader and move to GPU\n",
    "# batch_size = 32\n",
    "\n",
    "# X_dataset = TensorDataset(X_train_tensor, X_train_tensor)  # Using X_train_tensor for both input and target\n",
    "# X_loader = DataLoader(X_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# start_time = time.time()\n",
    "# # Example training loop\n",
    "# num_epochs = 20\n",
    "# for epoch in range(num_epochs):\n",
    "#     for data in X_loader:   \n",
    "#         #- AE\n",
    "#         inputs, targets = data[0].to(device), data[1].to(device)  # Move batch to GPU\n",
    "#         outputs = model(inputs)        \n",
    "#         #- DAE\n",
    "#         #inputs, targets = model.add_noise(data[0]).to(device), data[1].to(device)  # Move batch to GPU\n",
    "#         #outputs = model(inputs)             \n",
    "#         loss = criterion(outputs, targets)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# model.eval() \n",
    "# with torch.no_grad():\n",
    "#     #latent_representations = model.encode(X_test_tensor).cpu().numpy()\n",
    "#     latent_representations = model.encode(X_tensor).cpu().numpy()\n",
    "    \n",
    "# end_time = time.time()\n",
    "# print(\"AE Runtime: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c9efd-5988-41a7-af9c-fa85f996f3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#- use raw features\n",
    "# train_models_results(latent_representations,Y)\n",
    "\n",
    "#- umap now for plotting\n",
    "\n",
    "import umap.umap_ as umap\n",
    "clusterable_embedding_ae, runtime = umap_embedding(latent_representations, n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16672938-f7cc-43cf-a14d-f11133401fbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = y\n",
    "group = list(labels.unique())\n",
    "plot_umap_embedding(clusterable_embedding_ae, labels, group, colors=['orange', 'red', 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1cb50-024a-4662-bcf3-76ae2721e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(latent_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7aa001-bf35-4cf3-9bbf-f4a87c447fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(clusterable_embedding_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cf598-1fbd-49ae-b184-43ec23afef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save latent representation and embeddings to file\n",
    "# np.save(root_path + \"2025/data/latent_representations.npy\", latent_representations)\n",
    "# np.save(root_path + \"2025/data/clusterable_embedding_ae.npy\", clusterable_embedding_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d273683-28a1-46f7-b7d8-74d53f612d3d",
   "metadata": {},
   "source": [
    "# IX. CLUSTERING\n",
    "Using Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f7eb7-6f30-4f65-bae7-752fc920ee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2048ad7-a7fb-4fa8-8e5b-47a2c51ef33b",
   "metadata": {},
   "source": [
    "# X. FEATURE IMPORTANCE\n",
    "Using Logistic Regression and Shapley analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa5908-9ac1-4ee3-bde9-d31521a47d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36c608dc-bba7-4af4-b1bc-b26560891194",
   "metadata": {},
   "source": [
    "# XI. RISK ANALYSIS\n",
    "Using Kaplan-Meier (K-M) survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca416abe-b62f-4b08-bf5d-ae11d1ddc31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
