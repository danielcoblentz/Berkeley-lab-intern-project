{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c00e2f3-e09a-454c-9fe5-56c33eb944a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# import torch\n",
    "\n",
    "# from sklearn.model_selection import GroupShuffleSplit, ParameterGrid\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "# df = pd.read_csv('/global/cfs/projectdirs/m1532/Projects_MVP/_members/Daniel/2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_reduced_with_idCOPY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1e6f4d-794a-4eae-b3c8-a18e00e7f455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>group</th>\n",
       "      <th>group_name</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>los</th>\n",
       "      <th>age</th>\n",
       "      <th>charlson</th>\n",
       "      <th>bmi</th>\n",
       "      <th>...</th>\n",
       "      <th>insurance_Medicare</th>\n",
       "      <th>insurance_Other</th>\n",
       "      <th>admission_type_DIRECT EMER.</th>\n",
       "      <th>admission_type_DIRECT OBSERVATION</th>\n",
       "      <th>admission_type_ELECTIVE</th>\n",
       "      <th>admission_type_EU OBSERVATION</th>\n",
       "      <th>admission_type_EW EMER.</th>\n",
       "      <th>admission_type_OBSERVATION ADMIT</th>\n",
       "      <th>admission_type_SURGICAL SAME DAY ADMISSION</th>\n",
       "      <th>admission_type_URGENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19923</td>\n",
       "      <td>15369429</td>\n",
       "      <td>23575836</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344523</td>\n",
       "      <td>0.927879</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.503740</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26807</td>\n",
       "      <td>19509694</td>\n",
       "      <td>24812065</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237798</td>\n",
       "      <td>0.635849</td>\n",
       "      <td>0.639151</td>\n",
       "      <td>0.526197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51598</td>\n",
       "      <td>11296936</td>\n",
       "      <td>29328007</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272642</td>\n",
       "      <td>0.741347</td>\n",
       "      <td>0.683011</td>\n",
       "      <td>0.428018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21095</td>\n",
       "      <td>15184004</td>\n",
       "      <td>23783708</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432708</td>\n",
       "      <td>0.791799</td>\n",
       "      <td>0.683011</td>\n",
       "      <td>0.464120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52078</td>\n",
       "      <td>16846730</td>\n",
       "      <td>29416702</td>\n",
       "      <td>2</td>\n",
       "      <td>HF Only</td>\n",
       "      <td>0</td>\n",
       "      <td>0.102359</td>\n",
       "      <td>0.799803</td>\n",
       "      <td>0.639151</td>\n",
       "      <td>0.585216</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id  group group_name  hospital_expire_flag  \\\n",
       "0       19923    15369429  23575836      2    HF Only                     0   \n",
       "1       26807    19509694  24812065      2    HF Only                     0   \n",
       "2       51598    11296936  29328007      2    HF Only                     0   \n",
       "3       21095    15184004  23783708      2    HF Only                     0   \n",
       "4       52078    16846730  29416702      2    HF Only                     0   \n",
       "\n",
       "        los       age  charlson       bmi  ...  insurance_Medicare  \\\n",
       "0  0.344523  0.927879  0.721698  0.503740  ...                 1.0   \n",
       "1  0.237798  0.635849  0.639151  0.526197  ...                 1.0   \n",
       "2  0.272642  0.741347  0.683011  0.428018  ...                 1.0   \n",
       "3  0.432708  0.791799  0.683011  0.464120  ...                 1.0   \n",
       "4  0.102359  0.799803  0.639151  0.585216  ...                 1.0   \n",
       "\n",
       "   insurance_Other  admission_type_DIRECT EMER.  \\\n",
       "0              0.0                          0.0   \n",
       "1              0.0                          0.0   \n",
       "2              0.0                          0.0   \n",
       "3              0.0                          0.0   \n",
       "4              0.0                          0.0   \n",
       "\n",
       "   admission_type_DIRECT OBSERVATION  admission_type_ELECTIVE  \\\n",
       "0                                0.0                      0.0   \n",
       "1                                0.0                      0.0   \n",
       "2                                0.0                      0.0   \n",
       "3                                0.0                      0.0   \n",
       "4                                0.0                      0.0   \n",
       "\n",
       "   admission_type_EU OBSERVATION  admission_type_EW EMER.  \\\n",
       "0                            0.0                      1.0   \n",
       "1                            0.0                      1.0   \n",
       "2                            0.0                      1.0   \n",
       "3                            0.0                      1.0   \n",
       "4                            1.0                      0.0   \n",
       "\n",
       "   admission_type_OBSERVATION ADMIT  \\\n",
       "0                               0.0   \n",
       "1                               0.0   \n",
       "2                               0.0   \n",
       "3                               0.0   \n",
       "4                               0.0   \n",
       "\n",
       "   admission_type_SURGICAL SAME DAY ADMISSION  admission_type_URGENT  \n",
       "0                                         0.0                    0.0  \n",
       "1                                         0.0                    0.0  \n",
       "2                                         0.0                    0.0  \n",
       "3                                         0.0                    0.0  \n",
       "4                                         0.0                    0.0  \n",
       "\n",
       "[5 rows x 581 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed64d0d9-19b5-4647-b358-58fef407f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = df[\"subject_id\"].values\n",
    "# y_full = df[\"group\"].values\n",
    "\n",
    "# # Drop only the text‐label column; keep every other feature (including “Unnamed: 0” etc.)\n",
    "# X_full = df.drop(columns=[\"group_name\", \"subject_id\", \"group\"]).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5fc597-2cfe-4460-8050-257a7f82ce87",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437cd621-0c7d-4fe0-b875-911081beb83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 1/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'HF Only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 52\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning configuration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(grid)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m TabNetClassifier(\n\u001b[1;32m     42\u001b[0m     n_d\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_d\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     43\u001b[0m     n_a\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_a\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 52\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n\u001b[1;32m     62\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_valid, y_pred)\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:217\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m=\u001b[39m loss_fn\n\u001b[0;32m--> 217\u001b[0m \u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m check_warm_start(warm_start, from_unsupervised)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_fit_params(\n\u001b[1;32m    221\u001b[0m     X_train,\n\u001b[1;32m    222\u001b[0m     y_train,\n\u001b[1;32m    223\u001b[0m     eval_set,\n\u001b[1;32m    224\u001b[0m     weights,\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/utils.py:507\u001b[0m, in \u001b[0;36mcheck_input\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    505\u001b[0m     err_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas DataFrame are not supported: apply X.values when calling fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(err_message)\n\u001b[0;32m--> 507\u001b[0m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'HF Only'"
     ]
    }
   ],
   "source": [
    "# #base imports for search\n",
    "\n",
    "\n",
    "\n",
    "# #Separate out groups, labels, and features\n",
    "# groups = df[\"subject_id\"].values\n",
    "# y_full = df[\"group\"].values\n",
    "# X_full = df.drop(columns=[\"subject_id\", \"group\"]).values\n",
    "\n",
    "# # one train/validation split by patient\n",
    "# gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "# train_idx, valid_idx = next(gss.split(X_full, y_full, groups=groups))\n",
    "\n",
    "# X_train = X_full[train_idx]\n",
    "# y_train = y_full[train_idx]\n",
    "# X_valid = X_full[valid_idx]\n",
    "# y_valid = y_full[valid_idx]\n",
    "\n",
    "\n",
    "# # grid of TabNet hyperparameters\n",
    "# param_grid = {\n",
    "#     'n_d': [64, 128],\n",
    "#     'n_a': [64, 128],\n",
    "#     'n_steps': [3, 5],\n",
    "#     'gamma': [1.2, 1.5],\n",
    "#     'lr': [0.01, 0.02],\n",
    "#     'batch_size': [256, 512]\n",
    "# }\n",
    "# grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# results = []\n",
    "# best_acc = 0.0\n",
    "# best_params = None\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Run grid search\n",
    "# for i, params in enumerate(grid, 1):\n",
    "#     print(f\"\\nRunning configuration {i}/{len(grid)}: {params}\")\n",
    "    \n",
    "#     model = TabNetClassifier(\n",
    "#         n_d=params['n_d'],\n",
    "#         n_a=params['n_a'],\n",
    "#         n_steps=params['n_steps'],\n",
    "#         gamma=params['gamma'],\n",
    "#         optimizer_fn=torch.optim.Adam,\n",
    "#         optimizer_params=dict(lr=params['lr']),\n",
    "#         seed=42,\n",
    "#         verbose=0\n",
    "#     )\n",
    "\n",
    "#     model.fit(\n",
    "#         X_train, y_train,\n",
    "#         eval_set=[(X_valid, y_valid)],\n",
    "#         max_epochs=100,\n",
    "#         patience=10,\n",
    "#         batch_size=params['batch_size'],\n",
    "#         virtual_batch_size=min(128, params['batch_size'] // 2)\n",
    "#     )\n",
    "\n",
    "#     y_pred = model.predict(X_valid)\n",
    "#     acc = accuracy_score(y_valid, y_pred)\n",
    "#     results.append((params, acc))\n",
    "\n",
    "#     if acc > best_acc:\n",
    "#         best_acc = acc\n",
    "#         best_params = params\n",
    "\n",
    "# #save to file and show best config\n",
    "# pd.DataFrame(results, columns=[\"params\", \"accuracy\"]) \\\n",
    "#   .to_csv(\"tabnet_grid_results_by_patient.csv\", index=False)\n",
    "\n",
    "# print(\"\\nOptimal hyperparameters:\")\n",
    "# print(best_params)\n",
    "# print(f\"Best validation accuracy: {best_acc:.6f}\")\n",
    "# end_time = time.time()\n",
    "# print(f\"\\nTotal runtime: {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88552b20-608c-4fda-9b64-e8d5991484a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 1/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_accuracy = 0.74896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 2/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 3/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 4/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_accuracy = 0.75783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 5/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_accuracy = 0.75137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 6/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_accuracy = 0.75389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 7/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_accuracy = 0.7587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 8/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_accuracy = 0.75038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 9/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_accuracy = 0.75367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 10/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_accuracy = 0.75848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 11/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_accuracy = 0.76067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 12/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 13/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.76089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 14/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_accuracy = 0.7621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 15/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 16/64: {'batch_size': 256, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_accuracy = 0.75991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 17/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 18/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_accuracy = 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 19/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 20/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_accuracy = 0.75542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 21/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_accuracy = 0.75859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 22/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_accuracy = 0.75531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 23/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.75706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 24/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 25/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 26/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_accuracy = 0.75651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 27/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.75728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 28/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.76385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 29/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_accuracy = 0.75936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 30/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_accuracy = 0.76067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 31/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 32/64: {'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.76035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 33/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_accuracy = 0.74984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 34/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_accuracy = 0.75257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 35/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_accuracy = 0.74885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 36/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_accuracy = 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 37/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_accuracy = 0.75235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 38/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_accuracy = 0.75181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 39/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.74852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 40/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_accuracy = 0.75619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 41/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.75203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 42/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_accuracy = 0.75936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 43/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.75805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 44/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.75334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 45/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_accuracy = 0.75498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 46/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_accuracy = 0.75082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 47/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_accuracy = 0.75783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 48/64: {'batch_size': 512, 'gamma': 1.2, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_accuracy = 0.75257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 49/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_accuracy = 0.75695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 50/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_accuracy = 0.75224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 51/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_accuracy = 0.75323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 52/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_accuracy = 0.75301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 53/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_accuracy = 0.75049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 54/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_accuracy = 0.75454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 55/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_accuracy = 0.75422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 56/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.01, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_accuracy = 0.75071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 57/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.75159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 58/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_accuracy = 0.75192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 59/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.76024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 60/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_accuracy = 0.75848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 61/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_accuracy = 0.75805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 62/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 64, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_accuracy = 0.75323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 63/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 3}\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_accuracy = 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running configuration 64/64: {'batch_size': 512, 'gamma': 1.5, 'lr': 0.02, 'n_a': 128, 'n_d': 128, 'n_steps': 5}\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_accuracy = 0.75717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/dtc03/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal hyperparameters:\n",
      "{'batch_size': 256, 'gamma': 1.5, 'lr': 0.02, 'n_a': 64, 'n_d': 128, 'n_steps': 5}\n",
      "Best validation accuracy: 0.763849\n",
      "\n",
      "Total runtime: 18305.76 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ─── Load your data ─────────────────────────────────────────────────────────────\n",
    "# Replace the path below with the actual path to your CSV (or however you load df)\n",
    "df = pd.read_csv('/global/cfs/projectdirs/m1532/Projects_MVP/_members/Daniel/2025/cohort/osa_hf_demo_lab_diagnosis_medbinary_procedure_reduced_with_idCOPY.csv')\n",
    "\n",
    "# ─── Prepare features, labels, and groups ──────────────────────────────────────\n",
    "groups = df[\"subject_id\"].values\n",
    "y_full = df[\"group\"].values\n",
    "\n",
    "# Drop only the text‐label column; keep every other feature (including “Unnamed: 0” etc.)\n",
    "X_full = df.drop(columns=[\"group_name\", \"subject_id\", \"group\"]).values\n",
    "\n",
    "# ─── Train/validation split by patient ─────────────────────────────────────────\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "train_idx, valid_idx = next(gss.split(X_full, y_full, groups=groups))\n",
    "\n",
    "X_train = X_full[train_idx]\n",
    "y_train = y_full[train_idx]\n",
    "X_valid = X_full[valid_idx]\n",
    "y_valid = y_full[valid_idx]\n",
    "\n",
    "# ─── Define TabNet hyperparameter grid ─────────────────────────────────────────\n",
    "param_grid = {\n",
    "    'n_d':        [64, 128],\n",
    "    'n_a':        [64, 128],\n",
    "    'n_steps':    [3, 5],\n",
    "    'gamma':      [1.2, 1.5],\n",
    "    'lr':         [0.01, 0.02],\n",
    "    'batch_size': [256, 512]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# ─── Run the grid search ───────────────────────────────────────────────────────\n",
    "results     = []\n",
    "best_acc    = 0.0\n",
    "best_params = None\n",
    "start_time  = time.time()\n",
    "\n",
    "for i, params in enumerate(grid, 1):\n",
    "    print(f\"\\nRunning configuration {i}/{len(grid)}: {params}\")\n",
    "\n",
    "    model = TabNetClassifier(\n",
    "        n_d=params['n_d'],\n",
    "        n_a=params['n_a'],\n",
    "        n_steps=params['n_steps'],\n",
    "        gamma=params['gamma'],\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=params['lr']),\n",
    "        seed=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        max_epochs=100,\n",
    "        patience=10,\n",
    "        batch_size=params['batch_size'],\n",
    "        virtual_batch_size=min(128, params['batch_size'] // 2)\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    acc    = accuracy_score(y_valid, y_pred)\n",
    "    results.append((params, acc))\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc    = acc\n",
    "        best_params = params\n",
    "\n",
    "# ─── Save results and print summary ────────────────────────────────────────────\n",
    "pd.DataFrame(results, columns=[\"params\", \"accuracy\"]) \\\n",
    "  .to_csv(\"tabnet_grid_results_by_patient.csv\", index=False)\n",
    "\n",
    "print(\"\\nOptimal hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Best validation accuracy: {best_acc:.6f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal runtime: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2cc05-a7e5-4111-8f31-eb631fd59aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
